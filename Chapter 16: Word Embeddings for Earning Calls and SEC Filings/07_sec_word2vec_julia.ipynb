{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word vectors from SEC filings using Gensim: word2vec model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='direction:rtl; font-family: \"B Nazanin\"; font-size: 20px;'> \n",
    "در این نوت بوک، از داده‌های پیش‌پردازش شده در نوت بوک شماره ۶ (06_sec_preprocessing_julia.ipynb) استفاده شده است.\n",
    "بنابراین نیاز است که ابتدا آن نوت بوک اجرا شود."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using PyCall\n",
    "using Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Glob\")\n",
    "#Pkg.add(\"TextAnalysis\")\n",
    "#Pkg.add(\"DataFrames\")\n",
    "#Pkg.add(\"Plots\")\n",
    "#Pkg.add(\"CSV\")\n",
    "#Pkg.add(\"Seaborn\")\n",
    "#Pkg.add(\"ScikitLearn\")\n",
    "#Pkg.add(\"Embeddings\")\n",
    "#Pkg.add(\"JSON\")\n",
    "#Pkg.add(\"StatsBase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Glob\n",
    "using DataFrames\n",
    "using Plots\n",
    "using CSV\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conda.add(\"gensim\")\n",
    "@pyimport gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'gensim.models.phrases.FrozenPhrases'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word2Vec = gensim.models.Word2Vec\n",
    "KeyedVectors = gensim.models.KeyedVectors\n",
    "LineSentence = gensim.models.word2vec.LineSentence\n",
    "Phrases = gensim.models.phrases.Phrases\n",
    "Phraser = gensim.models.phrases.Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.decomposition._incremental_pca.IncrementalPCA'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ScikitLearn\n",
    "using ScikitLearn: @sk_import\n",
    "@sk_import decomposition: IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:57:53.399615Z",
     "start_time": "2020-06-21T14:57:53.391212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_time (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function format_time(t)\n",
    "    m = t ÷ 60\n",
    "    s = t % 60\n",
    "    h = m ÷ 60\n",
    "    m = m % 60\n",
    "    h = length(\"$h\") == 2 ? h : \"0$h\"\n",
    "    m = length(\"$m\") == 2 ? m : \"0$m\"\n",
    "    s = length(\"$s\") == 2 ? s : \"0$s\"\n",
    "    return \"$h:$m:$s\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:57:53.416919Z",
     "start_time": "2020-06-21T14:57:53.400799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"..\\\\data\\\\sec-filings\\\\ngrams\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_path = joinpath(\"..\", \"data\", \"sec-filings\")\n",
    "ngram_path = joinpath(sec_path, \"ngrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:57:53.426072Z",
     "start_time": "2020-06-21T14:57:53.418180Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = joinpath(\"results\", \"sec-filings\")\n",
    "\n",
    "model_path = joinpath(results_path, \"models\")\n",
    "\n",
    "if !(isdir(model_path))\n",
    "    mkpath(model_path)\n",
    "end\n",
    "\n",
    "log_path = joinpath(results_path, \"logs\")\n",
    "\n",
    "if !(isdir(log_path))\n",
    "    mkpath(log_path)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:33:56.321672Z",
     "start_time": "2020-06-21T15:33:56.319833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data\\\\analogies-en.txt\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogies_path = joinpath(\"data\", \"analogies-en.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Sentence Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:57:53.453489Z",
     "start_time": "2020-06-21T14:57:53.446620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NGRAMS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate memory-efficient text ingestion, the LineSentence class creates a generator from individual sentences contained in the provided text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T14:57:53.478441Z",
     "start_time": "2020-06-21T14:57:53.454500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <gensim.models.word2vec.LineSentence object at 0x000000005F213F40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_path = joinpath(ngram_path, \"ngrams_$(NGRAMS).txt\")\n",
    "sentences = LineSentence(sentence_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word2vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [gensim.models.word2vec](https://radimrehurek.com/gensim/models/word2vec.html) class implements the skipgram and CBOW architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:58.507035Z",
     "start_time": "2020-06-21T14:57:53.479312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 00:00:28\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "model = Word2Vec(sentences,\n",
    "                 sg=1,          # 1 for skip-gram; otherwise CBOW\n",
    "                 hs=0,          # hierarchical softmax if 1, negative sampling if 0\n",
    "                 vector_size=300,      # Vector dimensionality\n",
    "                 window=5,      # Max distance betw. current and predicted word\n",
    "                 min_count=50,  # Ignore words with lower frequency\n",
    "                 negative=15,    # noise word count for negative sampling\n",
    "                 workers=4,     # no threads \n",
    "                 epochs=1,        # no epochs = iterations over corpus\n",
    "                 alpha=0.05,   # initial learning rate\n",
    "                 min_alpha=0.0001 # final learning rate\n",
    "                ) \n",
    "println(\"Duration: $(format_time(floor(Int, time() - start)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist model & vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:58.739904Z",
     "start_time": "2020-06-21T15:24:58.508205Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(normpath(joinpath(model_path, \"word2vec_0.model\")))\n",
    "model.wv.save(normpath(joinpath(model_path, \"word_vectors_0.bin\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.036488Z",
     "start_time": "2020-06-21T15:24:58.756668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <gensim.models.word2vec.Word2Vec object at 0x00000000889BD730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec.load(normpath(joinpath(model_path, \"word2vec_0.model\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.294149Z",
     "start_time": "2020-06-21T15:24:59.038043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <gensim.models.keyedvectors.KeyedVectors object at 0x00000000889BDBE0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv = KeyedVectors.load(normpath(joinpath(model_path, \"word_vectors_0.bin\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.427873Z",
     "start_time": "2020-06-21T15:24:59.300032Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = Any[]\n",
    "for k ∈ model.wv.index_to_key\n",
    "    v_index = model.wv.key_to_index[k]\n",
    "    v_count = model.wv.get_vecattr(k, \"count\")\n",
    "    push!(vocab, [k, v_index, v_count])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.477941Z",
     "start_time": "2020-06-21T15:24:59.429275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>token</th><th>idx</th><th>count</th></tr><tr><th></th><th>String</th><th>Int64</th><th>PyObject</th></tr></thead><tbody><p>5,805 rows × 3 columns</p><tr><th>1</th><td>million</td><td>0</td><td>PyObject 34435</td></tr><tr><th>2</th><td>company</td><td>1</td><td>PyObject 28594</td></tr><tr><th>3</th><td>financial</td><td>2</td><td>PyObject 24424</td></tr><tr><th>4</th><td>business</td><td>3</td><td>PyObject 22824</td></tr><tr><th>5</th><td>products</td><td>4</td><td>PyObject 22240</td></tr><tr><th>6</th><td>s</td><td>5</td><td>PyObject 20488</td></tr><tr><th>7</th><td>operations</td><td>6</td><td>PyObject 17778</td></tr><tr><th>8</th><td>net</td><td>7</td><td>PyObject 16563</td></tr><tr><th>9</th><td>sales</td><td>8</td><td>PyObject 16511</td></tr><tr><th>10</th><td>market</td><td>9</td><td>PyObject 16322</td></tr><tr><th>11</th><td>year</td><td>10</td><td>PyObject 16086</td></tr><tr><th>12</th><td>interest</td><td>11</td><td>PyObject 15951</td></tr><tr><th>13</th><td>cash</td><td>12</td><td>PyObject 15713</td></tr><tr><th>14</th><td>including</td><td>13</td><td>PyObject 15671</td></tr><tr><th>15</th><td>december</td><td>14</td><td>PyObject 14955</td></tr><tr><th>16</th><td>income</td><td>15</td><td>PyObject 14709</td></tr><tr><th>17</th><td>results</td><td>16</td><td>PyObject 14642</td></tr><tr><th>18</th><td>operating</td><td>17</td><td>PyObject 14235</td></tr><tr><th>19</th><td>capital</td><td>18</td><td>PyObject 13841</td></tr><tr><th>20</th><td>product</td><td>19</td><td>PyObject 13756</td></tr><tr><th>21</th><td>new</td><td>20</td><td>PyObject 13347</td></tr><tr><th>22</th><td>costs</td><td>21</td><td>PyObject 13282</td></tr><tr><th>23</th><td>assets</td><td>22</td><td>PyObject 12953</td></tr><tr><th>24</th><td>tax</td><td>23</td><td>PyObject 12951</td></tr><tr><th>25</th><td>stock</td><td>24</td><td>PyObject 12892</td></tr><tr><th>26</th><td>future</td><td>25</td><td>PyObject 12800</td></tr><tr><th>27</th><td>related</td><td>26</td><td>PyObject 12687</td></tr><tr><th>28</th><td>based</td><td>27</td><td>PyObject 12461</td></tr><tr><th>29</th><td>certain</td><td>28</td><td>PyObject 12119</td></tr><tr><th>30</th><td>value</td><td>29</td><td>PyObject 11873</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& token & idx & count\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & PyObject\\\\\n",
       "\t\\hline\n",
       "\t1 & million & 0 & PyObject 34435 \\\\\n",
       "\t2 & company & 1 & PyObject 28594 \\\\\n",
       "\t3 & financial & 2 & PyObject 24424 \\\\\n",
       "\t4 & business & 3 & PyObject 22824 \\\\\n",
       "\t5 & products & 4 & PyObject 22240 \\\\\n",
       "\t6 & s & 5 & PyObject 20488 \\\\\n",
       "\t7 & operations & 6 & PyObject 17778 \\\\\n",
       "\t8 & net & 7 & PyObject 16563 \\\\\n",
       "\t9 & sales & 8 & PyObject 16511 \\\\\n",
       "\t10 & market & 9 & PyObject 16322 \\\\\n",
       "\t11 & year & 10 & PyObject 16086 \\\\\n",
       "\t12 & interest & 11 & PyObject 15951 \\\\\n",
       "\t13 & cash & 12 & PyObject 15713 \\\\\n",
       "\t14 & including & 13 & PyObject 15671 \\\\\n",
       "\t15 & december & 14 & PyObject 14955 \\\\\n",
       "\t16 & income & 15 & PyObject 14709 \\\\\n",
       "\t17 & results & 16 & PyObject 14642 \\\\\n",
       "\t18 & operating & 17 & PyObject 14235 \\\\\n",
       "\t19 & capital & 18 & PyObject 13841 \\\\\n",
       "\t20 & product & 19 & PyObject 13756 \\\\\n",
       "\t21 & new & 20 & PyObject 13347 \\\\\n",
       "\t22 & costs & 21 & PyObject 13282 \\\\\n",
       "\t23 & assets & 22 & PyObject 12953 \\\\\n",
       "\t24 & tax & 23 & PyObject 12951 \\\\\n",
       "\t25 & stock & 24 & PyObject 12892 \\\\\n",
       "\t26 & future & 25 & PyObject 12800 \\\\\n",
       "\t27 & related & 26 & PyObject 12687 \\\\\n",
       "\t28 & based & 27 & PyObject 12461 \\\\\n",
       "\t29 & certain & 28 & PyObject 12119 \\\\\n",
       "\t30 & value & 29 & PyObject 11873 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5805×3 DataFrame\n",
       "│ Row  │ token        │ idx   │ count          │\n",
       "│      │ \u001b[90mString\u001b[39m       │ \u001b[90mInt64\u001b[39m │ \u001b[90mPyObject\u001b[39m       │\n",
       "├──────┼──────────────┼───────┼────────────────┤\n",
       "│ 1    │ million      │ 0     │ PyObject 34435 │\n",
       "│ 2    │ company      │ 1     │ PyObject 28594 │\n",
       "│ 3    │ financial    │ 2     │ PyObject 24424 │\n",
       "│ 4    │ business     │ 3     │ PyObject 22824 │\n",
       "│ 5    │ products     │ 4     │ PyObject 22240 │\n",
       "│ 6    │ s            │ 5     │ PyObject 20488 │\n",
       "│ 7    │ operations   │ 6     │ PyObject 17778 │\n",
       "│ 8    │ net          │ 7     │ PyObject 16563 │\n",
       "│ 9    │ sales        │ 8     │ PyObject 16511 │\n",
       "│ 10   │ market       │ 9     │ PyObject 16322 │\n",
       "⋮\n",
       "│ 5795 │ pbm          │ 5794  │ PyObject 50    │\n",
       "│ 5796 │ eunice       │ 5795  │ PyObject 50    │\n",
       "│ 5797 │ pik          │ 5796  │ PyObject 50    │\n",
       "│ 5798 │ viewing      │ 5797  │ PyObject 50    │\n",
       "│ 5799 │ thermal      │ 5798  │ PyObject 50    │\n",
       "│ 5800 │ undivided    │ 5799  │ PyObject 50    │\n",
       "│ 5801 │ pillar       │ 5800  │ PyObject 50    │\n",
       "│ 5802 │ discouraging │ 5801  │ PyObject 50    │\n",
       "│ 5803 │ transporting │ 5802  │ PyObject 50    │\n",
       "│ 5804 │ loaned       │ 5803  │ PyObject 50    │\n",
       "│ 5805 │ assists      │ 5804  │ PyObject 50    │"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sort!(DataFrame(token=[v[1] for v in vocab], \n",
    "                        idx=[v[2] for v in vocab], \n",
    "                        count=[v[3] for v in vocab]), :count, rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.520332Z",
     "start_time": "2020-06-21T15:24:59.513350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>token</th><th>idx</th><th>count</th></tr><tr><th></th><th>String</th><th>Int64</th><th>PyObject</th></tr></thead><tbody><p>10 rows × 3 columns</p><tr><th>1</th><td>million</td><td>0</td><td>PyObject 34435</td></tr><tr><th>2</th><td>company</td><td>1</td><td>PyObject 28594</td></tr><tr><th>3</th><td>financial</td><td>2</td><td>PyObject 24424</td></tr><tr><th>4</th><td>business</td><td>3</td><td>PyObject 22824</td></tr><tr><th>5</th><td>products</td><td>4</td><td>PyObject 22240</td></tr><tr><th>6</th><td>s</td><td>5</td><td>PyObject 20488</td></tr><tr><th>7</th><td>operations</td><td>6</td><td>PyObject 17778</td></tr><tr><th>8</th><td>net</td><td>7</td><td>PyObject 16563</td></tr><tr><th>9</th><td>sales</td><td>8</td><td>PyObject 16511</td></tr><tr><th>10</th><td>market</td><td>9</td><td>PyObject 16322</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& token & idx & count\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & PyObject\\\\\n",
       "\t\\hline\n",
       "\t1 & million & 0 & PyObject 34435 \\\\\n",
       "\t2 & company & 1 & PyObject 28594 \\\\\n",
       "\t3 & financial & 2 & PyObject 24424 \\\\\n",
       "\t4 & business & 3 & PyObject 22824 \\\\\n",
       "\t5 & products & 4 & PyObject 22240 \\\\\n",
       "\t6 & s & 5 & PyObject 20488 \\\\\n",
       "\t7 & operations & 6 & PyObject 17778 \\\\\n",
       "\t8 & net & 7 & PyObject 16563 \\\\\n",
       "\t9 & sales & 8 & PyObject 16511 \\\\\n",
       "\t10 & market & 9 & PyObject 16322 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×3 DataFrame\n",
       "│ Row │ token      │ idx   │ count          │\n",
       "│     │ \u001b[90mString\u001b[39m     │ \u001b[90mInt64\u001b[39m │ \u001b[90mPyObject\u001b[39m       │\n",
       "├─────┼────────────┼───────┼────────────────┤\n",
       "│ 1   │ million    │ 0     │ PyObject 34435 │\n",
       "│ 2   │ company    │ 1     │ PyObject 28594 │\n",
       "│ 3   │ financial  │ 2     │ PyObject 24424 │\n",
       "│ 4   │ business   │ 3     │ PyObject 22824 │\n",
       "│ 5   │ products   │ 4     │ PyObject 22240 │\n",
       "│ 6   │ s          │ 5     │ PyObject 20488 │\n",
       "│ 7   │ operations │ 6     │ PyObject 17778 │\n",
       "│ 8   │ net        │ 7     │ PyObject 16563 │\n",
       "│ 9   │ sales      │ 8     │ PyObject 16511 │\n",
       "│ 10  │ market     │ 9     │ PyObject 16322 │"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(vocab, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.545436Z",
     "start_time": "2020-06-21T15:24:59.521405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Stats:\n",
      "Length:         5805\n",
      "Type:           PyObject\n",
      "Number Unique:  1497\n"
     ]
    }
   ],
   "source": [
    "describe(vocab[\"count\"])\n",
    "#.describe(percentiles=np.arange(.1, 1, .1)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:34:04.826106Z",
     "start_time": "2020-06-21T15:34:04.819570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy_by_category (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function accuracy_by_category(acc; detail=true)\n",
    "    results = [[c[\"section\"], length(c[\"correct\"]), length(c[\"incorrect\"])] for c ∈ acc]\n",
    "    results = DataFrame(category=[result[1] for result ∈ results], \n",
    "                        correct=[result[2] for result ∈ results], \n",
    "                        incorrect=[result[3] for result ∈ results])\n",
    "                        \n",
    "    results[!, \"average\"] = results.correct./sum.(eachrow(results[:, [\"correct\", \"incorrect\"]]))\n",
    "    if detail\n",
    "        println(sort(results, :average, rev=true))\n",
    "    end\n",
    "    return convert(Array, filter(:category => ==(\"Total accuracy\"), results))[2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:34:58.842380Z",
     "start_time": "2020-06-21T15:34:05.044496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Dict{Any, Any}}:\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"capital-common-countries\")\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"capital-world\")\n",
       " Dict(\"incorrect\" => [(\"CHICAGO\", \"ILLINOIS\", \"HOUSTON\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"DALLAS\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CHICAGO\", \"ILLINOIS\", \"SEATTLE\", \"WASHINGTON\"), (\"CHICAGO\", \"ILLINOIS\", \"CINCINNATI\", \"OHIO\"), (\"HOUSTON\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"HOUSTON\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"HOUSTON\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"HOUSTON\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"DALLAS\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\")  …  (\"SEATTLE\", \"WASHINGTON\", \"ATLANTA\", \"GEORGIA\"), (\"SEATTLE\", \"WASHINGTON\", \"CINCINNATI\", \"OHIO\"), (\"ATLANTA\", \"GEORGIA\", \"HOUSTON\", \"TEXAS\"), (\"ATLANTA\", \"GEORGIA\", \"DALLAS\", \"TEXAS\"), (\"ATLANTA\", \"GEORGIA\", \"SEATTLE\", \"WASHINGTON\"), (\"ATLANTA\", \"GEORGIA\", \"CINCINNATI\", \"OHIO\"), (\"CINCINNATI\", \"OHIO\", \"HOUSTON\", \"TEXAS\"), (\"CINCINNATI\", \"OHIO\", \"DALLAS\", \"TEXAS\"), (\"CINCINNATI\", \"OHIO\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CINCINNATI\", \"OHIO\", \"SEATTLE\", \"WASHINGTON\")], \"correct\" => [(\"CHICAGO\", \"ILLINOIS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"DALLAS\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"BOSTON\", \"MASSACHUSETTS\", \"CHICAGO\", \"ILLINOIS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"ATLANTA\", \"GEORGIA\"), (\"ATLANTA\", \"GEORGIA\", \"CHICAGO\", \"ILLINOIS\"), (\"ATLANTA\", \"GEORGIA\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CINCINNATI\", \"OHIO\", \"CHICAGO\", \"ILLINOIS\"), (\"CINCINNATI\", \"OHIO\", \"ATLANTA\", \"GEORGIA\")], \"section\" => \"city-in-state\")\n",
       " Dict(\"incorrect\" => [(\"BRAZIL\", \"REAL\", \"CANADA\", \"DOLLAR\"), (\"BRAZIL\", \"REAL\", \"EUROPE\", \"EURO\"), (\"BRAZIL\", \"REAL\", \"JAPAN\", \"YEN\"), (\"BRAZIL\", \"REAL\", \"USA\", \"DOLLAR\"), (\"CANADA\", \"DOLLAR\", \"BRAZIL\", \"REAL\"), (\"CANADA\", \"DOLLAR\", \"EUROPE\", \"EURO\"), (\"CANADA\", \"DOLLAR\", \"JAPAN\", \"YEN\"), (\"EUROPE\", \"EURO\", \"BRAZIL\", \"REAL\"), (\"EUROPE\", \"EURO\", \"CANADA\", \"DOLLAR\"), (\"EUROPE\", \"EURO\", \"JAPAN\", \"YEN\"), (\"EUROPE\", \"EURO\", \"USA\", \"DOLLAR\"), (\"JAPAN\", \"YEN\", \"BRAZIL\", \"REAL\"), (\"JAPAN\", \"YEN\", \"CANADA\", \"DOLLAR\"), (\"JAPAN\", \"YEN\", \"EUROPE\", \"EURO\"), (\"JAPAN\", \"YEN\", \"USA\", \"DOLLAR\"), (\"USA\", \"DOLLAR\", \"BRAZIL\", \"REAL\"), (\"USA\", \"DOLLAR\", \"EUROPE\", \"EURO\"), (\"USA\", \"DOLLAR\", \"JAPAN\", \"YEN\")], \"correct\" => Any[], \"section\" => \"currency\")\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"family\")\n",
       " Dict(\"incorrect\" => [(\"COMPLETE\", \"COMPLETELY\", \"EFFICIENT\", \"EFFICIENTLY\"), (\"COMPLETE\", \"COMPLETELY\", \"IMMEDIATE\", \"IMMEDIATELY\"), (\"COMPLETE\", \"COMPLETELY\", \"POSSIBLE\", \"POSSIBLY\"), (\"COMPLETE\", \"COMPLETELY\", \"QUICK\", \"QUICKLY\"), (\"COMPLETE\", \"COMPLETELY\", \"RAPID\", \"RAPIDLY\"), (\"COMPLETE\", \"COMPLETELY\", \"SLOW\", \"SLOWLY\"), (\"COMPLETE\", \"COMPLETELY\", \"TYPICAL\", \"TYPICALLY\"), (\"COMPLETE\", \"COMPLETELY\", \"USUAL\", \"USUALLY\"), (\"EFFICIENT\", \"EFFICIENTLY\", \"COMPLETE\", \"COMPLETELY\"), (\"EFFICIENT\", \"EFFICIENTLY\", \"IMMEDIATE\", \"IMMEDIATELY\")  …  (\"TYPICAL\", \"TYPICALLY\", \"SLOW\", \"SLOWLY\"), (\"TYPICAL\", \"TYPICALLY\", \"USUAL\", \"USUALLY\"), (\"USUAL\", \"USUALLY\", \"COMPLETE\", \"COMPLETELY\"), (\"USUAL\", \"USUALLY\", \"EFFICIENT\", \"EFFICIENTLY\"), (\"USUAL\", \"USUALLY\", \"IMMEDIATE\", \"IMMEDIATELY\"), (\"USUAL\", \"USUALLY\", \"POSSIBLE\", \"POSSIBLY\"), (\"USUAL\", \"USUALLY\", \"QUICK\", \"QUICKLY\"), (\"USUAL\", \"USUALLY\", \"RAPID\", \"RAPIDLY\"), (\"USUAL\", \"USUALLY\", \"SLOW\", \"SLOWLY\"), (\"USUAL\", \"USUALLY\", \"TYPICAL\", \"TYPICALLY\")], \"correct\" => Any[], \"section\" => \"gram1-adjective-to-adverb\")\n",
       " Dict(\"incorrect\" => [(\"ACCEPTABLE\", \"UNACCEPTABLE\", \"CERTAIN\", \"UNCERTAIN\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"CONSISTENT\", \"INCONSISTENT\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"KNOWN\", \"UNKNOWN\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"LIKELY\", \"UNLIKELY\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"POSSIBLE\", \"IMPOSSIBLE\"), (\"CERTAIN\", \"UNCERTAIN\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"CERTAIN\", \"UNCERTAIN\", \"CONSISTENT\", \"INCONSISTENT\"), (\"CERTAIN\", \"UNCERTAIN\", \"KNOWN\", \"UNKNOWN\"), (\"CERTAIN\", \"UNCERTAIN\", \"LIKELY\", \"UNLIKELY\"), (\"CERTAIN\", \"UNCERTAIN\", \"POSSIBLE\", \"IMPOSSIBLE\")  …  (\"LIKELY\", \"UNLIKELY\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"LIKELY\", \"UNLIKELY\", \"CERTAIN\", \"UNCERTAIN\"), (\"LIKELY\", \"UNLIKELY\", \"CONSISTENT\", \"INCONSISTENT\"), (\"LIKELY\", \"UNLIKELY\", \"KNOWN\", \"UNKNOWN\"), (\"LIKELY\", \"UNLIKELY\", \"POSSIBLE\", \"IMPOSSIBLE\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"CERTAIN\", \"UNCERTAIN\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"CONSISTENT\", \"INCONSISTENT\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"KNOWN\", \"UNKNOWN\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"LIKELY\", \"UNLIKELY\")], \"correct\" => Any[], \"section\" => \"gram2-opposite\")\n",
       " Dict(\"incorrect\" => [(\"EASY\", \"EASIER\", \"FAST\", \"FASTER\"), (\"EASY\", \"EASIER\", \"GOOD\", \"BETTER\"), (\"EASY\", \"EASIER\", \"GREAT\", \"GREATER\"), (\"EASY\", \"EASIER\", \"HIGH\", \"HIGHER\"), (\"EASY\", \"EASIER\", \"LARGE\", \"LARGER\"), (\"EASY\", \"EASIER\", \"LONG\", \"LONGER\"), (\"EASY\", \"EASIER\", \"LOW\", \"LOWER\"), (\"EASY\", \"EASIER\", \"NEW\", \"NEWER\"), (\"EASY\", \"EASIER\", \"OLD\", \"OLDER\"), (\"EASY\", \"EASIER\", \"SHORT\", \"SHORTER\")  …  (\"WIDE\", \"WIDER\", \"HIGH\", \"HIGHER\"), (\"WIDE\", \"WIDER\", \"LONG\", \"LONGER\"), (\"WIDE\", \"WIDER\", \"LOW\", \"LOWER\"), (\"WIDE\", \"WIDER\", \"NEW\", \"NEWER\"), (\"WIDE\", \"WIDER\", \"OLD\", \"OLDER\"), (\"WIDE\", \"WIDER\", \"SHORT\", \"SHORTER\"), (\"WIDE\", \"WIDER\", \"SLOW\", \"SLOWER\"), (\"WIDE\", \"WIDER\", \"SMALL\", \"SMALLER\"), (\"WIDE\", \"WIDER\", \"STRONG\", \"STRONGER\"), (\"WIDE\", \"WIDER\", \"WEAK\", \"WEAKER\")], \"correct\" => [(\"GREAT\", \"GREATER\", \"LARGE\", \"LARGER\"), (\"HIGH\", \"HIGHER\", \"LOW\", \"LOWER\"), (\"LARGE\", \"LARGER\", \"WIDE\", \"WIDER\"), (\"LOW\", \"LOWER\", \"HIGH\", \"HIGHER\"), (\"SMALL\", \"SMALLER\", \"LARGE\", \"LARGER\"), (\"STRONG\", \"STRONGER\", \"LARGE\", \"LARGER\"), (\"WIDE\", \"WIDER\", \"LARGE\", \"LARGER\")], \"section\" => \"gram3-comparative\")\n",
       " Dict(\"incorrect\" => [(\"GOOD\", \"BEST\", \"GREAT\", \"GREATEST\"), (\"GOOD\", \"BEST\", \"HIGH\", \"HIGHEST\"), (\"GOOD\", \"BEST\", \"LARGE\", \"LARGEST\"), (\"GOOD\", \"BEST\", \"LOW\", \"LOWEST\"), (\"GREAT\", \"GREATEST\", \"GOOD\", \"BEST\"), (\"GREAT\", \"GREATEST\", \"HIGH\", \"HIGHEST\"), (\"GREAT\", \"GREATEST\", \"LARGE\", \"LARGEST\"), (\"GREAT\", \"GREATEST\", \"LOW\", \"LOWEST\"), (\"HIGH\", \"HIGHEST\", \"GOOD\", \"BEST\"), (\"HIGH\", \"HIGHEST\", \"GREAT\", \"GREATEST\"), (\"HIGH\", \"HIGHEST\", \"LARGE\", \"LARGEST\"), (\"HIGH\", \"HIGHEST\", \"LOW\", \"LOWEST\"), (\"LARGE\", \"LARGEST\", \"GOOD\", \"BEST\"), (\"LARGE\", \"LARGEST\", \"GREAT\", \"GREATEST\"), (\"LARGE\", \"LARGEST\", \"HIGH\", \"HIGHEST\"), (\"LARGE\", \"LARGEST\", \"LOW\", \"LOWEST\"), (\"LOW\", \"LOWEST\", \"GOOD\", \"BEST\"), (\"LOW\", \"LOWEST\", \"GREAT\", \"GREATEST\"), (\"LOW\", \"LOWEST\", \"HIGH\", \"HIGHEST\"), (\"LOW\", \"LOWEST\", \"LARGE\", \"LARGEST\")], \"correct\" => Any[], \"section\" => \"gram4-superlative\")\n",
       " Dict(\"incorrect\" => [(\"DECREASE\", \"DECREASING\", \"ENHANCE\", \"ENHANCING\"), (\"DECREASE\", \"DECREASING\", \"GENERATE\", \"GENERATING\"), (\"DECREASE\", \"DECREASING\", \"IMPLEMENT\", \"IMPLEMENTING\"), (\"DECREASE\", \"DECREASING\", \"INCREASE\", \"INCREASING\"), (\"DECREASE\", \"DECREASING\", \"LOOK\", \"LOOKING\"), (\"DECREASE\", \"DECREASING\", \"READ\", \"READING\"), (\"DECREASE\", \"DECREASING\", \"RUN\", \"RUNNING\"), (\"DECREASE\", \"DECREASING\", \"WRITE\", \"WRITING\"), (\"ENHANCE\", \"ENHANCING\", \"DECREASE\", \"DECREASING\"), (\"ENHANCE\", \"ENHANCING\", \"GENERATE\", \"GENERATING\")  …  (\"RUN\", \"RUNNING\", \"READ\", \"READING\"), (\"RUN\", \"RUNNING\", \"WRITE\", \"WRITING\"), (\"WRITE\", \"WRITING\", \"DECREASE\", \"DECREASING\"), (\"WRITE\", \"WRITING\", \"ENHANCE\", \"ENHANCING\"), (\"WRITE\", \"WRITING\", \"GENERATE\", \"GENERATING\"), (\"WRITE\", \"WRITING\", \"IMPLEMENT\", \"IMPLEMENTING\"), (\"WRITE\", \"WRITING\", \"INCREASE\", \"INCREASING\"), (\"WRITE\", \"WRITING\", \"LOOK\", \"LOOKING\"), (\"WRITE\", \"WRITING\", \"READ\", \"READING\"), (\"WRITE\", \"WRITING\", \"RUN\", \"RUNNING\")], \"correct\" => [(\"GENERATE\", \"GENERATING\", \"IMPLEMENT\", \"IMPLEMENTING\")], \"section\" => \"gram5-present-participle\")\n",
       " Dict(\"incorrect\" => [(\"BRAZIL\", \"BRAZILIAN\", \"CHINA\", \"CHINESE\"), (\"BRAZIL\", \"BRAZILIAN\", \"GERMANY\", \"GERMAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"ISRAEL\", \"ISRAELI\"), (\"BRAZIL\", \"BRAZILIAN\", \"KOREA\", \"KOREAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"MEXICO\", \"MEXICAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"RUSSIA\", \"RUSSIAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"SWITZERLAND\", \"SWISS\"), (\"CHINA\", \"CHINESE\", \"BRAZIL\", \"BRAZILIAN\"), (\"CHINA\", \"CHINESE\", \"GERMANY\", \"GERMAN\"), (\"CHINA\", \"CHINESE\", \"INDIA\", \"INDIAN\")  …  (\"RUSSIA\", \"RUSSIAN\", \"SWITZERLAND\", \"SWISS\"), (\"SWITZERLAND\", \"SWISS\", \"BRAZIL\", \"BRAZILIAN\"), (\"SWITZERLAND\", \"SWISS\", \"CHINA\", \"CHINESE\"), (\"SWITZERLAND\", \"SWISS\", \"GERMANY\", \"GERMAN\"), (\"SWITZERLAND\", \"SWISS\", \"INDIA\", \"INDIAN\"), (\"SWITZERLAND\", \"SWISS\", \"ISRAEL\", \"ISRAELI\"), (\"SWITZERLAND\", \"SWISS\", \"JAPAN\", \"JAPANESE\"), (\"SWITZERLAND\", \"SWISS\", \"KOREA\", \"KOREAN\"), (\"SWITZERLAND\", \"SWISS\", \"MEXICO\", \"MEXICAN\"), (\"SWITZERLAND\", \"SWISS\", \"RUSSIA\", \"RUSSIAN\")], \"correct\" => [(\"BRAZIL\", \"BRAZILIAN\", \"INDIA\", \"INDIAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"JAPAN\", \"JAPANESE\"), (\"CHINA\", \"CHINESE\", \"KOREA\", \"KOREAN\"), (\"GERMANY\", \"GERMAN\", \"JAPAN\", \"JAPANESE\"), (\"GERMANY\", \"GERMAN\", \"KOREA\", \"KOREAN\"), (\"INDIA\", \"INDIAN\", \"BRAZIL\", \"BRAZILIAN\"), (\"INDIA\", \"INDIAN\", \"CHINA\", \"CHINESE\"), (\"INDIA\", \"INDIAN\", \"KOREA\", \"KOREAN\"), (\"INDIA\", \"INDIAN\", \"SWITZERLAND\", \"SWISS\"), (\"MEXICO\", \"MEXICAN\", \"CHINA\", \"CHINESE\"), (\"MEXICO\", \"MEXICAN\", \"KOREA\", \"KOREAN\"), (\"MEXICO\", \"MEXICAN\", \"SWITZERLAND\", \"SWISS\")], \"section\" => \"gram6-nationality-adjective\")\n",
       " Dict(\"incorrect\" => [(\"DECREASING\", \"DECREASED\", \"ENHANCING\", \"ENHANCED\"), (\"DECREASING\", \"DECREASED\", \"GENERATING\", \"GENERATED\"), (\"DECREASING\", \"DECREASED\", \"IMPLEMENTING\", \"IMPLEMENTED\"), (\"DECREASING\", \"DECREASED\", \"INCREASING\", \"INCREASED\"), (\"DECREASING\", \"DECREASED\", \"MOVING\", \"MOVED\"), (\"DECREASING\", \"DECREASED\", \"PAYING\", \"PAID\"), (\"DECREASING\", \"DECREASED\", \"READING\", \"READ\"), (\"DECREASING\", \"DECREASED\", \"SELLING\", \"SOLD\"), (\"DECREASING\", \"DECREASED\", \"SPENDING\", \"SPENT\"), (\"DECREASING\", \"DECREASED\", \"TAKING\", \"TOOK\")  …  (\"TAKING\", \"TOOK\", \"DECREASING\", \"DECREASED\"), (\"TAKING\", \"TOOK\", \"ENHANCING\", \"ENHANCED\"), (\"TAKING\", \"TOOK\", \"GENERATING\", \"GENERATED\"), (\"TAKING\", \"TOOK\", \"IMPLEMENTING\", \"IMPLEMENTED\"), (\"TAKING\", \"TOOK\", \"INCREASING\", \"INCREASED\"), (\"TAKING\", \"TOOK\", \"MOVING\", \"MOVED\"), (\"TAKING\", \"TOOK\", \"PAYING\", \"PAID\"), (\"TAKING\", \"TOOK\", \"READING\", \"READ\"), (\"TAKING\", \"TOOK\", \"SELLING\", \"SOLD\"), (\"TAKING\", \"TOOK\", \"SPENDING\", \"SPENT\")], \"correct\" => Any[], \"section\" => \"gram7-past-tense\")\n",
       " Dict(\"incorrect\" => [(\"BUILDING\", \"BUILDINGS\", \"COMPUTER\", \"COMPUTERS\"), (\"BUILDING\", \"BUILDINGS\", \"DOLLAR\", \"DOLLARS\"), (\"BUILDING\", \"BUILDINGS\", \"MACHINE\", \"MACHINES\"), (\"BUILDING\", \"BUILDINGS\", \"MAN\", \"MEN\"), (\"CAR\", \"CARS\", \"BUILDING\", \"BUILDINGS\"), (\"CAR\", \"CARS\", \"COMPUTER\", \"COMPUTERS\"), (\"CAR\", \"CARS\", \"DOLLAR\", \"DOLLARS\"), (\"CAR\", \"CARS\", \"MACHINE\", \"MACHINES\"), (\"CAR\", \"CARS\", \"MAN\", \"MEN\"), (\"COMPUTER\", \"COMPUTERS\", \"BUILDING\", \"BUILDINGS\")  …  (\"DOLLAR\", \"DOLLARS\", \"MAN\", \"MEN\"), (\"MACHINE\", \"MACHINES\", \"CAR\", \"CARS\"), (\"MACHINE\", \"MACHINES\", \"COMPUTER\", \"COMPUTERS\"), (\"MACHINE\", \"MACHINES\", \"DOLLAR\", \"DOLLARS\"), (\"MACHINE\", \"MACHINES\", \"MAN\", \"MEN\"), (\"MAN\", \"MEN\", \"BUILDING\", \"BUILDINGS\"), (\"MAN\", \"MEN\", \"CAR\", \"CARS\"), (\"MAN\", \"MEN\", \"COMPUTER\", \"COMPUTERS\"), (\"MAN\", \"MEN\", \"DOLLAR\", \"DOLLARS\"), (\"MAN\", \"MEN\", \"MACHINE\", \"MACHINES\")], \"correct\" => [(\"BUILDING\", \"BUILDINGS\", \"CAR\", \"CARS\"), (\"COMPUTER\", \"COMPUTERS\", \"CAR\", \"CARS\"), (\"DOLLAR\", \"DOLLARS\", \"CAR\", \"CARS\"), (\"MACHINE\", \"MACHINES\", \"BUILDING\", \"BUILDINGS\")], \"section\" => \"gram8-plural\")\n",
       " Dict(\"incorrect\" => [(\"DECREASE\", \"DECREASES\", \"DESCRIBE\", \"DESCRIBES\"), (\"DECREASE\", \"DECREASES\", \"ENHANCE\", \"ENHANCES\"), (\"DECREASE\", \"DECREASES\", \"ESTIMATE\", \"ESTIMATES\"), (\"DECREASE\", \"DECREASES\", \"GENERATE\", \"GENERATES\"), (\"DECREASE\", \"DECREASES\", \"PROVIDE\", \"PROVIDES\"), (\"DECREASE\", \"DECREASES\", \"WORK\", \"WORKS\"), (\"DESCRIBE\", \"DESCRIBES\", \"DECREASE\", \"DECREASES\"), (\"DESCRIBE\", \"DESCRIBES\", \"ENHANCE\", \"ENHANCES\"), (\"DESCRIBE\", \"DESCRIBES\", \"ESTIMATE\", \"ESTIMATES\"), (\"DESCRIBE\", \"DESCRIBES\", \"GENERATE\", \"GENERATES\")  …  (\"PROVIDE\", \"PROVIDES\", \"PLAY\", \"PLAYS\"), (\"PROVIDE\", \"PROVIDES\", \"WORK\", \"WORKS\"), (\"WORK\", \"WORKS\", \"DECREASE\", \"DECREASES\"), (\"WORK\", \"WORKS\", \"DESCRIBE\", \"DESCRIBES\"), (\"WORK\", \"WORKS\", \"ENHANCE\", \"ENHANCES\"), (\"WORK\", \"WORKS\", \"ESTIMATE\", \"ESTIMATES\"), (\"WORK\", \"WORKS\", \"GENERATE\", \"GENERATES\"), (\"WORK\", \"WORKS\", \"INCREASE\", \"INCREASES\"), (\"WORK\", \"WORKS\", \"PLAY\", \"PLAYS\"), (\"WORK\", \"WORKS\", \"PROVIDE\", \"PROVIDES\")], \"correct\" => [(\"DECREASE\", \"DECREASES\", \"INCREASE\", \"INCREASES\"), (\"DECREASE\", \"DECREASES\", \"PLAY\", \"PLAYS\"), (\"ENHANCE\", \"ENHANCES\", \"ESTIMATE\", \"ESTIMATES\"), (\"ESTIMATE\", \"ESTIMATES\", \"PLAY\", \"PLAYS\"), (\"INCREASE\", \"INCREASES\", \"DECREASE\", \"DECREASES\"), (\"INCREASE\", \"INCREASES\", \"PLAY\", \"PLAYS\")], \"section\" => \"gram9-plural-verbs\")\n",
       " Dict(\"incorrect\" => [(\"CHICAGO\", \"ILLINOIS\", \"HOUSTON\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"DALLAS\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CHICAGO\", \"ILLINOIS\", \"SEATTLE\", \"WASHINGTON\"), (\"CHICAGO\", \"ILLINOIS\", \"CINCINNATI\", \"OHIO\"), (\"HOUSTON\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"HOUSTON\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"HOUSTON\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"HOUSTON\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"DALLAS\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\")  …  (\"PROVIDE\", \"PROVIDES\", \"PLAY\", \"PLAYS\"), (\"PROVIDE\", \"PROVIDES\", \"WORK\", \"WORKS\"), (\"WORK\", \"WORKS\", \"DECREASE\", \"DECREASES\"), (\"WORK\", \"WORKS\", \"DESCRIBE\", \"DESCRIBES\"), (\"WORK\", \"WORKS\", \"ENHANCE\", \"ENHANCES\"), (\"WORK\", \"WORKS\", \"ESTIMATE\", \"ESTIMATES\"), (\"WORK\", \"WORKS\", \"GENERATE\", \"GENERATES\"), (\"WORK\", \"WORKS\", \"INCREASE\", \"INCREASES\"), (\"WORK\", \"WORKS\", \"PLAY\", \"PLAYS\"), (\"WORK\", \"WORKS\", \"PROVIDE\", \"PROVIDES\")], \"correct\" => [(\"CHICAGO\", \"ILLINOIS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"DALLAS\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"BOSTON\", \"MASSACHUSETTS\", \"CHICAGO\", \"ILLINOIS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"ATLANTA\", \"GEORGIA\"), (\"ATLANTA\", \"GEORGIA\", \"CHICAGO\", \"ILLINOIS\"), (\"ATLANTA\", \"GEORGIA\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CINCINNATI\", \"OHIO\", \"CHICAGO\", \"ILLINOIS\"), (\"CINCINNATI\", \"OHIO\", \"ATLANTA\", \"GEORGIA\"), (\"GREAT\", \"GREATER\", \"LARGE\", \"LARGER\")  …  (\"BUILDING\", \"BUILDINGS\", \"CAR\", \"CARS\"), (\"COMPUTER\", \"COMPUTERS\", \"CAR\", \"CARS\"), (\"DOLLAR\", \"DOLLARS\", \"CAR\", \"CARS\"), (\"MACHINE\", \"MACHINES\", \"BUILDING\", \"BUILDINGS\"), (\"DECREASE\", \"DECREASES\", \"INCREASE\", \"INCREASES\"), (\"DECREASE\", \"DECREASES\", \"PLAY\", \"PLAYS\"), (\"ENHANCE\", \"ENHANCES\", \"ESTIMATE\", \"ESTIMATES\"), (\"ESTIMATE\", \"ESTIMATES\", \"PLAY\", \"PLAYS\"), (\"INCREASE\", \"INCREASES\", \"DECREASE\", \"DECREASES\"), (\"INCREASE\", \"INCREASES\", \"PLAY\", \"PLAYS\")], \"section\" => \"Total accuracy\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_accuracy = model.wv.evaluate_word_analogies(normpath(analogies_path), case_insensitive=true)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:34:58.861949Z",
     "start_time": "2020-06-21T15:34:58.843367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15×4 DataFrame\n",
      "│ Row │ category                    │ correct │ incorrect │ average   │\n",
      "│     │ \u001b[90mString\u001b[39m                      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n",
      "├─────┼─────────────────────────────┼─────────┼───────────┼───────────┤\n",
      "│ 1   │ capital-common-countries    │ 0       │ 0         │ NaN       │\n",
      "│ 2   │ capital-world               │ 0       │ 0         │ NaN       │\n",
      "│ 3   │ family                      │ 0       │ 0         │ NaN       │\n",
      "│ 4   │ city-in-state               │ 9       │ 31        │ 0.225     │\n",
      "│ 5   │ gram6-nationality-adjective │ 12      │ 78        │ 0.133333  │\n",
      "│ 6   │ gram8-plural                │ 4       │ 26        │ 0.133333  │\n",
      "│ 7   │ gram9-plural-verbs          │ 6       │ 66        │ 0.0833333 │\n",
      "│ 8   │ Total accuracy              │ 39      │ 755       │ 0.0491184 │\n",
      "│ 9   │ gram3-comparative           │ 7       │ 233       │ 0.0291667 │\n",
      "│ 10  │ gram5-present-participle    │ 1       │ 71        │ 0.0138889 │\n",
      "│ 11  │ currency                    │ 0       │ 18        │ 0.0       │\n",
      "│ 12  │ gram1-adjective-to-adverb   │ 0       │ 72        │ 0.0       │\n",
      "│ 13  │ gram2-opposite              │ 0       │ 30        │ 0.0       │\n",
      "│ 14  │ gram4-superlative           │ 0       │ 20        │ 0.0       │\n",
      "│ 15  │ gram7-past-tense            │ 0       │ 110       │ 0.0       │\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Any}:\n",
       "  39\n",
       " 755\n",
       "   0.0491183879093199"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = accuracy_by_category(detailed_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:34:58.879346Z",
     "start_time": "2020-06-21T15:34:58.863357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_analogies (generic function with 2 methods)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_analogies(w2v, max_vocab=15000)\n",
    "    accuracy = w2v.wv.evaluate_word_analogies(analogies_path, restrict_vocab=15000, case_insensitive=true)[2]\n",
    "    \n",
    "    results = [[c[\"section\"], length(c[\"correct\"]), length(c[\"incorrect\"])] for c ∈ accuracy]\n",
    "    results = DataFrame(category=[result[1] for result ∈ results], \n",
    "                        correct=[result[2] for result ∈ results], \n",
    "                        incorrect=[result[3] for result ∈ results])\n",
    "    \n",
    "    results[!, \"average\"] = results.correct./sum.(eachrow(results[:, [\"correct\", \"incorrect\"]]))\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:34:58.883984Z",
     "start_time": "2020-06-21T15:34:58.880915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function total_accuracy(w2v)\n",
    "    df = eval_analogies(w2v)\n",
    "    return convert(Array, filter(:category => ==(\"Total accuracy\"), results))[2:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:35:16.240602Z",
     "start_time": "2020-06-21T15:34:58.885201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>category</th><th>correct</th><th>incorrect</th><th>average</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>15 rows × 4 columns</p><tr><th>1</th><td>capital-common-countries</td><td>0</td><td>0</td><td>NaN</td></tr><tr><th>2</th><td>capital-world</td><td>0</td><td>0</td><td>NaN</td></tr><tr><th>3</th><td>city-in-state</td><td>9</td><td>31</td><td>0.225</td></tr><tr><th>4</th><td>currency</td><td>0</td><td>18</td><td>0.0</td></tr><tr><th>5</th><td>family</td><td>0</td><td>0</td><td>NaN</td></tr><tr><th>6</th><td>gram1-adjective-to-adverb</td><td>0</td><td>72</td><td>0.0</td></tr><tr><th>7</th><td>gram2-opposite</td><td>0</td><td>30</td><td>0.0</td></tr><tr><th>8</th><td>gram3-comparative</td><td>7</td><td>233</td><td>0.0291667</td></tr><tr><th>9</th><td>gram4-superlative</td><td>0</td><td>20</td><td>0.0</td></tr><tr><th>10</th><td>gram5-present-participle</td><td>1</td><td>71</td><td>0.0138889</td></tr><tr><th>11</th><td>gram6-nationality-adjective</td><td>12</td><td>78</td><td>0.133333</td></tr><tr><th>12</th><td>gram7-past-tense</td><td>0</td><td>110</td><td>0.0</td></tr><tr><th>13</th><td>gram8-plural</td><td>4</td><td>26</td><td>0.133333</td></tr><tr><th>14</th><td>gram9-plural-verbs</td><td>6</td><td>66</td><td>0.0833333</td></tr><tr><th>15</th><td>Total accuracy</td><td>39</td><td>755</td><td>0.0491184</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& category & correct & incorrect & average\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & capital-common-countries & 0 & 0 & NaN \\\\\n",
       "\t2 & capital-world & 0 & 0 & NaN \\\\\n",
       "\t3 & city-in-state & 9 & 31 & 0.225 \\\\\n",
       "\t4 & currency & 0 & 18 & 0.0 \\\\\n",
       "\t5 & family & 0 & 0 & NaN \\\\\n",
       "\t6 & gram1-adjective-to-adverb & 0 & 72 & 0.0 \\\\\n",
       "\t7 & gram2-opposite & 0 & 30 & 0.0 \\\\\n",
       "\t8 & gram3-comparative & 7 & 233 & 0.0291667 \\\\\n",
       "\t9 & gram4-superlative & 0 & 20 & 0.0 \\\\\n",
       "\t10 & gram5-present-participle & 1 & 71 & 0.0138889 \\\\\n",
       "\t11 & gram6-nationality-adjective & 12 & 78 & 0.133333 \\\\\n",
       "\t12 & gram7-past-tense & 0 & 110 & 0.0 \\\\\n",
       "\t13 & gram8-plural & 4 & 26 & 0.133333 \\\\\n",
       "\t14 & gram9-plural-verbs & 6 & 66 & 0.0833333 \\\\\n",
       "\t15 & Total accuracy & 39 & 755 & 0.0491184 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "15×4 DataFrame\n",
       "│ Row │ category                    │ correct │ incorrect │ average   │\n",
       "│     │ \u001b[90mString\u001b[39m                      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n",
       "├─────┼─────────────────────────────┼─────────┼───────────┼───────────┤\n",
       "│ 1   │ capital-common-countries    │ 0       │ 0         │ NaN       │\n",
       "│ 2   │ capital-world               │ 0       │ 0         │ NaN       │\n",
       "│ 3   │ city-in-state               │ 9       │ 31        │ 0.225     │\n",
       "│ 4   │ currency                    │ 0       │ 18        │ 0.0       │\n",
       "│ 5   │ family                      │ 0       │ 0         │ NaN       │\n",
       "│ 6   │ gram1-adjective-to-adverb   │ 0       │ 72        │ 0.0       │\n",
       "│ 7   │ gram2-opposite              │ 0       │ 30        │ 0.0       │\n",
       "│ 8   │ gram3-comparative           │ 7       │ 233       │ 0.0291667 │\n",
       "│ 9   │ gram4-superlative           │ 0       │ 20        │ 0.0       │\n",
       "│ 10  │ gram5-present-participle    │ 1       │ 71        │ 0.0138889 │\n",
       "│ 11  │ gram6-nationality-adjective │ 12      │ 78        │ 0.133333  │\n",
       "│ 12  │ gram7-past-tense            │ 0       │ 110       │ 0.0       │\n",
       "│ 13  │ gram8-plural                │ 4       │ 26        │ 0.133333  │\n",
       "│ 14  │ gram9-plural-verbs          │ 6       │ 66        │ 0.0833333 │\n",
       "│ 15  │ Total accuracy              │ 39      │ 755       │ 0.0491184 │"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = eval_analogies(model)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Vector Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:35:16.256130Z",
     "start_time": "2020-06-21T15:35:16.241718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10×2 DataFrame\n",
      "│ Row │ term        │ similarity │\n",
      "│     │ \u001b[90mString\u001b[39m      │ \u001b[90mFloat64\u001b[39m    │\n",
      "├─────┼─────────────┼────────────┤\n",
      "│ 1   │ email       │ 0.837282   │\n",
      "│ 2   │ portal      │ 0.836035   │\n",
      "│ 3   │ voice       │ 0.802948   │\n",
      "│ 4   │ touch       │ 0.791997   │\n",
      "│ 5   │ communicate │ 0.78348    │\n",
      "│ 6   │ transmit    │ 0.779755   │\n",
      "│ 7   │ notebook    │ 0.77374    │\n",
      "│ 8   │ windows     │ 0.768419   │\n",
      "│ 9   │ viewing     │ 0.767883   │\n",
      "│ 10  │ pcie        │ 0.761672   │\n"
     ]
    }
   ],
   "source": [
    "sims = model.wv.most_similar(positive=[\"phone\"], restrict_vocab=15000)\n",
    "sims_df = DataFrame(term=[pair[1] for pair ∈ sims], \n",
    "                        similarity=[pair[2] for pair ∈ sims])\n",
    "println(sims_df)\n",
    "#print(pd.DataFrame(sims, columns=[\"term\", \"similarity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:35:16.279303Z",
     "start_time": "2020-06-21T15:35:16.257107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10×2 DataFrame\n",
      "│ Row │ term        │ similarity │\n",
      "│     │ \u001b[90mString\u001b[39m      │ \u001b[90mFloat64\u001b[39m    │\n",
      "├─────┼─────────────┼────────────┤\n",
      "│ 1   │ switzerland │ 0.861892   │\n",
      "│ 2   │ germany     │ 0.835466   │\n",
      "│ 3   │ netherlands │ 0.82592    │\n",
      "│ 4   │ zealand     │ 0.817587   │\n",
      "│ 5   │ india       │ 0.816676   │\n",
      "│ 6   │ thailand    │ 0.810973   │\n",
      "│ 7   │ belgium     │ 0.810843   │\n",
      "│ 8   │ kingdom     │ 0.808075   │\n",
      "│ 9   │ australia   │ 0.798887   │\n",
      "│ 10  │ sweden      │ 0.798025   │\n"
     ]
    }
   ],
   "source": [
    "analogy = model.wv.most_similar(positive=[\"france\", \"london\"], \n",
    "                                negative=[\"london\"], \n",
    "                                restrict_vocab=15000)\n",
    "\n",
    "analogy_df = DataFrame(term=[pair[1] for pair ∈ analogy], \n",
    "                        similarity=[pair[2] for pair ∈ analogy])\n",
    "println(analogy_df)\n",
    "#print(pd.DataFrame(analogy, columns=[\"term\", \"similarity\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check similarity for random words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:35:29.289819Z",
     "start_time": "2020-06-21T15:35:29.227163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>new</th><th>assets</th><th>value</th><th>development</th><th>significant</th></tr><tr><th></th><th>String</th><th>String</th><th>String</th><th>String</th><th>String</th></tr></thead><tbody><p>10 rows × 5 columns</p><tr><th>1</th><td>existing</td><td>realizability</td><td>fair</td><td>research</td><td>substantial</td></tr><tr><th>2</th><td>enhancements</td><td>intangible</td><td>values</td><td>advancement</td><td>expend</td></tr><tr><th>3</th><td>innovations</td><td>liabilities</td><td>windset</td><td>biomaterials</td><td>considerable</td></tr><tr><th>4</th><td>introduce</td><td>recoverability</td><td>carrying</td><td>landec</td><td>predicted</td></tr><tr><th>5</th><td>hcf</td><td>existed</td><td>valuing</td><td>ideas</td><td>burden</td></tr><tr><th>6</th><td>biomaterials</td><td>asset</td><td>allocating</td><td>digitaloptics</td><td>perceptions</td></tr><tr><th>7</th><td>adapt</td><td>resolor</td><td>approximates</td><td>engineering</td><td>strain</td></tr><tr><th>8</th><td>eim</td><td>goodwill</td><td>implied</td><td>ew</td><td>unsuccessful</td></tr><tr><th>9</th><td>nfs</td><td>reversal</td><td>ars</td><td>garp</td><td>defiance</td></tr><tr><th>10</th><td>introductions</td><td>depreciated</td><td>difference</td><td>centennial</td><td>reputational</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& new & assets & value & development & significant\\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & existing & realizability & fair & research & substantial \\\\\n",
       "\t2 & enhancements & intangible & values & advancement & expend \\\\\n",
       "\t3 & innovations & liabilities & windset & biomaterials & considerable \\\\\n",
       "\t4 & introduce & recoverability & carrying & landec & predicted \\\\\n",
       "\t5 & hcf & existed & valuing & ideas & burden \\\\\n",
       "\t6 & biomaterials & asset & allocating & digitaloptics & perceptions \\\\\n",
       "\t7 & adapt & resolor & approximates & engineering & strain \\\\\n",
       "\t8 & eim & goodwill & implied & ew & unsuccessful \\\\\n",
       "\t9 & nfs & reversal & ars & garp & defiance \\\\\n",
       "\t10 & introductions & depreciated & difference & centennial & reputational \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×5 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ new           │ assets         │ value        │ development   │\n",
       "│     │ \u001b[90mString\u001b[39m        │ \u001b[90mString\u001b[39m         │ \u001b[90mString\u001b[39m       │ \u001b[90mString\u001b[39m        │\n",
       "├─────┼───────────────┼────────────────┼──────────────┼───────────────┤\n",
       "│ 1   │ existing      │ realizability  │ fair         │ research      │\n",
       "│ 2   │ enhancements  │ intangible     │ values       │ advancement   │\n",
       "│ 3   │ innovations   │ liabilities    │ windset      │ biomaterials  │\n",
       "│ 4   │ introduce     │ recoverability │ carrying     │ landec        │\n",
       "│ 5   │ hcf           │ existed        │ valuing      │ ideas         │\n",
       "│ 6   │ biomaterials  │ asset          │ allocating   │ digitaloptics │\n",
       "│ 7   │ adapt         │ resolor        │ approximates │ engineering   │\n",
       "│ 8   │ eim           │ goodwill       │ implied      │ ew            │\n",
       "│ 9   │ nfs           │ reversal       │ ars          │ garp          │\n",
       "│ 10  │ introductions │ depreciated    │ difference   │ centennial    │"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALID_SET = 5  # Random set of words to get nearest neighbors for\n",
    "VALID_WINDOW = 100  # Most frequent words to draw validation set from\n",
    "valid_examples = StatsBase.sample(1:VALID_WINDOW, VALID_SET, replace=false)\n",
    "similars = DataFrame()\n",
    "\n",
    "for id ∈ sort(valid_examples)\n",
    "    word = vocab[id, \"token\"]\n",
    "    similars[word] = [s[1] for s ∈ model.wv.most_similar(word)]\n",
    "end\n",
    "similars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-22T03:12:37.505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | Duration: 00.0:00.0:024.515000104904175 | Accuracy: 0.060453400503778336 \n",
      "2 | Duration: 00.0:00.0:022.170000076293945 | Accuracy: 0.08060453400503778 \n",
      "3 | Duration: 00.0:00.0:023.908999919891357 | Accuracy: 0.07934508816120907 \n",
      "4 | Duration: 00.0:00.0:033.63499999046326 | Accuracy: 0.08438287153652393 \n",
      "5 | Duration: 00.0:00.0:036.91000008583069 | Accuracy: 0.08438287153652393 \n",
      "6 | Duration: 00.0:00.0:035.60199999809265 | Accuracy: 0.1070528967254408 \n",
      "7 | Duration: 00.0:00.0:031.34999990463257 | Accuracy: 0.0818639798488665 \n",
      "8 | Duration: 00.0:00.0:029.175000190734863 | Accuracy: 0.09445843828715365 \n",
      "9 | Duration: 00.0:00.0:028.111000061035156 | Accuracy: 0.10075566750629723 \n",
      "10 | Duration: 00.0:00.0:032.92199993133545 | Accuracy: 0.09193954659949623 \n",
      "11 | Duration: 00.0:00.0:033.99000000953674 | Accuracy: 0.09949622166246852 \n",
      "12 | Duration: 00.0:00.0:032.57200002670288 | Accuracy: 0.10957178841309824 \n",
      "13 | Duration: 00.0:00.0:030.29100012779236 | Accuracy: 0.11209068010075567 \n",
      "14 | Duration: 00.0:00.0:029.384999990463257 | Accuracy: 0.10957178841309824 \n"
     ]
    }
   ],
   "source": [
    "accuracies = [summary]\n",
    "best_accuracy = summary[end]\n",
    "for i ∈ 1:14\n",
    "    start = time()\n",
    "    model.train(sentences, epochs=1, total_examples=model.corpus_count)\n",
    "    detailed_accuracy = model.wv.evaluate_word_analogies(analogies_path)[2]\n",
    "    push!(accuracies, accuracy_by_category(detailed_accuracy, detail=false))\n",
    "    \n",
    "    println(\"$(i) | Duration: $(format_time(time() - start)) | Accuracy: $(accuracies[end][end]) \")\n",
    "    \n",
    "    if accuracies[end][end] > best_accuracy\n",
    "        model.save(normpath(joinpath(model_path, \"word2vec_$(i).model\")))\n",
    "        model.wv.save(normpath(joinpath(model_path, \"word_vectors_$(i).bin\")))\n",
    "        best_accuracy = accuracies[end][end]\n",
    "    end\n",
    "    \n",
    "    accuracies_df = DataFrame(correct=[accuracy[1] for accuracy ∈ accuracies], \n",
    "                            wrong=[accuracy[2] for accuracy ∈ accuracies], \n",
    "                            average=[accuracy[3] for accuracy ∈ accuracies])\n",
    "    CSV.write(joinpath(model_path, \"accuracies.csv\"), accuracies_df)\n",
    "end\n",
    "model.wv.save(normpath(joinpath(model_path, \"word_vectors_final.bin\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Epoch|Duration| Accuracy|\n",
    "|---|---|---|\n",
    "01 | 00:14:00 | 31.64% | \n",
    "02 | 00:14:21 | 31.72% | \n",
    "03 | 00:14:34 | 33.65% | \n",
    "04 | 00:16:11 | 34.03% | \n",
    "05 | 00:13:51 | 33.04% | \n",
    "06 | 00:13:46 | 33.28% | \n",
    "07 | 00:13:51 | 33.10% | \n",
    "08 | 00:13:54 | 34.11% | \n",
    "09 | 00:13:54 | 33.70% | \n",
    "10 | 00:13:55 | 34.09% | \n",
    "11 | 00:13:57 | 35.06% | \n",
    "12 | 00:13:38 | 33.79% | \n",
    "13 | 00:13:26 | 32.40% | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-22T03:12:50.880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"results\\\\sec-filings\\\\accuracies.csv\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_df = DataFrame(correct=[accuracy[1] for accuracy ∈ accuracies], \n",
    "                            wrong=[accuracy[2] for accuracy ∈ accuracies], \n",
    "                            average=[accuracy[3] for accuracy ∈ accuracies])\n",
    "\n",
    "CSV.write(joinpath(results_path, \"accuracies.csv\"), accuracies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.759064Z",
     "start_time": "2020-06-21T14:57:52.725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <gensim.models.word2vec.Word2Vec object at 0x000000008849CF10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Word2Vec.load(normpath(joinpath(model_path, \"word2vec_12.model\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.759787Z",
     "start_time": "2020-06-21T14:57:52.726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Dict{Any, Any}}:\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"capital-common-countries\")\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"capital-world\")\n",
       " Dict(\"incorrect\" => [(\"CHICAGO\", \"ILLINOIS\", \"DALLAS\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"SEATTLE\", \"WASHINGTON\"), (\"CHICAGO\", \"ILLINOIS\", \"CINCINNATI\", \"OHIO\"), (\"HOUSTON\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"HOUSTON\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"DALLAS\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"DALLAS\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"DALLAS\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"BOSTON\", \"MASSACHUSETTS\", \"HOUSTON\", \"TEXAS\")  …  (\"BOSTON\", \"MASSACHUSETTS\", \"SEATTLE\", \"WASHINGTON\"), (\"BOSTON\", \"MASSACHUSETTS\", \"CINCINNATI\", \"OHIO\"), (\"SEATTLE\", \"WASHINGTON\", \"HOUSTON\", \"TEXAS\"), (\"SEATTLE\", \"WASHINGTON\", \"DALLAS\", \"TEXAS\"), (\"SEATTLE\", \"WASHINGTON\", \"ATLANTA\", \"GEORGIA\"), (\"ATLANTA\", \"GEORGIA\", \"DALLAS\", \"TEXAS\"), (\"ATLANTA\", \"GEORGIA\", \"SEATTLE\", \"WASHINGTON\"), (\"ATLANTA\", \"GEORGIA\", \"CINCINNATI\", \"OHIO\"), (\"CINCINNATI\", \"OHIO\", \"HOUSTON\", \"TEXAS\"), (\"CINCINNATI\", \"OHIO\", \"DALLAS\", \"TEXAS\")], \"correct\" => [(\"CHICAGO\", \"ILLINOIS\", \"HOUSTON\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CHICAGO\", \"ILLINOIS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"HOUSTON\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"DALLAS\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"DALLAS\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"CHICAGO\", \"ILLINOIS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"ATLANTA\", \"GEORGIA\"), (\"SEATTLE\", \"WASHINGTON\", \"CHICAGO\", \"ILLINOIS\"), (\"SEATTLE\", \"WASHINGTON\", \"BOSTON\", \"MASSACHUSETTS\"), (\"SEATTLE\", \"WASHINGTON\", \"CINCINNATI\", \"OHIO\"), (\"ATLANTA\", \"GEORGIA\", \"CHICAGO\", \"ILLINOIS\"), (\"ATLANTA\", \"GEORGIA\", \"HOUSTON\", \"TEXAS\"), (\"ATLANTA\", \"GEORGIA\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CINCINNATI\", \"OHIO\", \"CHICAGO\", \"ILLINOIS\"), (\"CINCINNATI\", \"OHIO\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CINCINNATI\", \"OHIO\", \"SEATTLE\", \"WASHINGTON\"), (\"CINCINNATI\", \"OHIO\", \"ATLANTA\", \"GEORGIA\")], \"section\" => \"city-in-state\")\n",
       " Dict(\"incorrect\" => [(\"BRAZIL\", \"REAL\", \"CANADA\", \"DOLLAR\"), (\"BRAZIL\", \"REAL\", \"EUROPE\", \"EURO\"), (\"BRAZIL\", \"REAL\", \"JAPAN\", \"YEN\"), (\"BRAZIL\", \"REAL\", \"USA\", \"DOLLAR\"), (\"CANADA\", \"DOLLAR\", \"BRAZIL\", \"REAL\"), (\"CANADA\", \"DOLLAR\", \"EUROPE\", \"EURO\"), (\"CANADA\", \"DOLLAR\", \"JAPAN\", \"YEN\"), (\"EUROPE\", \"EURO\", \"BRAZIL\", \"REAL\"), (\"EUROPE\", \"EURO\", \"CANADA\", \"DOLLAR\"), (\"EUROPE\", \"EURO\", \"JAPAN\", \"YEN\"), (\"EUROPE\", \"EURO\", \"USA\", \"DOLLAR\"), (\"JAPAN\", \"YEN\", \"BRAZIL\", \"REAL\"), (\"JAPAN\", \"YEN\", \"CANADA\", \"DOLLAR\"), (\"JAPAN\", \"YEN\", \"EUROPE\", \"EURO\"), (\"JAPAN\", \"YEN\", \"USA\", \"DOLLAR\"), (\"USA\", \"DOLLAR\", \"BRAZIL\", \"REAL\"), (\"USA\", \"DOLLAR\", \"EUROPE\", \"EURO\"), (\"USA\", \"DOLLAR\", \"JAPAN\", \"YEN\")], \"correct\" => Any[], \"section\" => \"currency\")\n",
       " Dict(\"incorrect\" => Any[], \"correct\" => Any[], \"section\" => \"family\")\n",
       " Dict(\"incorrect\" => [(\"COMPLETE\", \"COMPLETELY\", \"EFFICIENT\", \"EFFICIENTLY\"), (\"COMPLETE\", \"COMPLETELY\", \"IMMEDIATE\", \"IMMEDIATELY\"), (\"COMPLETE\", \"COMPLETELY\", \"POSSIBLE\", \"POSSIBLY\"), (\"COMPLETE\", \"COMPLETELY\", \"QUICK\", \"QUICKLY\"), (\"COMPLETE\", \"COMPLETELY\", \"RAPID\", \"RAPIDLY\"), (\"COMPLETE\", \"COMPLETELY\", \"SLOW\", \"SLOWLY\"), (\"COMPLETE\", \"COMPLETELY\", \"TYPICAL\", \"TYPICALLY\"), (\"COMPLETE\", \"COMPLETELY\", \"USUAL\", \"USUALLY\"), (\"EFFICIENT\", \"EFFICIENTLY\", \"COMPLETE\", \"COMPLETELY\"), (\"EFFICIENT\", \"EFFICIENTLY\", \"IMMEDIATE\", \"IMMEDIATELY\")  …  (\"TYPICAL\", \"TYPICALLY\", \"RAPID\", \"RAPIDLY\"), (\"TYPICAL\", \"TYPICALLY\", \"SLOW\", \"SLOWLY\"), (\"TYPICAL\", \"TYPICALLY\", \"USUAL\", \"USUALLY\"), (\"USUAL\", \"USUALLY\", \"COMPLETE\", \"COMPLETELY\"), (\"USUAL\", \"USUALLY\", \"EFFICIENT\", \"EFFICIENTLY\"), (\"USUAL\", \"USUALLY\", \"IMMEDIATE\", \"IMMEDIATELY\"), (\"USUAL\", \"USUALLY\", \"POSSIBLE\", \"POSSIBLY\"), (\"USUAL\", \"USUALLY\", \"QUICK\", \"QUICKLY\"), (\"USUAL\", \"USUALLY\", \"RAPID\", \"RAPIDLY\"), (\"USUAL\", \"USUALLY\", \"SLOW\", \"SLOWLY\")], \"correct\" => [(\"USUAL\", \"USUALLY\", \"TYPICAL\", \"TYPICALLY\")], \"section\" => \"gram1-adjective-to-adverb\")\n",
       " Dict(\"incorrect\" => [(\"ACCEPTABLE\", \"UNACCEPTABLE\", \"CERTAIN\", \"UNCERTAIN\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"CONSISTENT\", \"INCONSISTENT\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"KNOWN\", \"UNKNOWN\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"LIKELY\", \"UNLIKELY\"), (\"ACCEPTABLE\", \"UNACCEPTABLE\", \"POSSIBLE\", \"IMPOSSIBLE\"), (\"CERTAIN\", \"UNCERTAIN\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"CERTAIN\", \"UNCERTAIN\", \"CONSISTENT\", \"INCONSISTENT\"), (\"CERTAIN\", \"UNCERTAIN\", \"KNOWN\", \"UNKNOWN\"), (\"CERTAIN\", \"UNCERTAIN\", \"LIKELY\", \"UNLIKELY\"), (\"CERTAIN\", \"UNCERTAIN\", \"POSSIBLE\", \"IMPOSSIBLE\")  …  (\"LIKELY\", \"UNLIKELY\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"LIKELY\", \"UNLIKELY\", \"CERTAIN\", \"UNCERTAIN\"), (\"LIKELY\", \"UNLIKELY\", \"CONSISTENT\", \"INCONSISTENT\"), (\"LIKELY\", \"UNLIKELY\", \"KNOWN\", \"UNKNOWN\"), (\"LIKELY\", \"UNLIKELY\", \"POSSIBLE\", \"IMPOSSIBLE\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"ACCEPTABLE\", \"UNACCEPTABLE\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"CERTAIN\", \"UNCERTAIN\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"CONSISTENT\", \"INCONSISTENT\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"KNOWN\", \"UNKNOWN\"), (\"POSSIBLE\", \"IMPOSSIBLE\", \"LIKELY\", \"UNLIKELY\")], \"correct\" => Any[], \"section\" => \"gram2-opposite\")\n",
       " Dict(\"incorrect\" => [(\"EASY\", \"EASIER\", \"FAST\", \"FASTER\"), (\"EASY\", \"EASIER\", \"GOOD\", \"BETTER\"), (\"EASY\", \"EASIER\", \"GREAT\", \"GREATER\"), (\"EASY\", \"EASIER\", \"HIGH\", \"HIGHER\"), (\"EASY\", \"EASIER\", \"LONG\", \"LONGER\"), (\"EASY\", \"EASIER\", \"LOW\", \"LOWER\"), (\"EASY\", \"EASIER\", \"NEW\", \"NEWER\"), (\"EASY\", \"EASIER\", \"OLD\", \"OLDER\"), (\"EASY\", \"EASIER\", \"SHORT\", \"SHORTER\"), (\"EASY\", \"EASIER\", \"SLOW\", \"SLOWER\")  …  (\"WIDE\", \"WIDER\", \"HIGH\", \"HIGHER\"), (\"WIDE\", \"WIDER\", \"LONG\", \"LONGER\"), (\"WIDE\", \"WIDER\", \"LOW\", \"LOWER\"), (\"WIDE\", \"WIDER\", \"NEW\", \"NEWER\"), (\"WIDE\", \"WIDER\", \"OLD\", \"OLDER\"), (\"WIDE\", \"WIDER\", \"SHORT\", \"SHORTER\"), (\"WIDE\", \"WIDER\", \"SLOW\", \"SLOWER\"), (\"WIDE\", \"WIDER\", \"SMALL\", \"SMALLER\"), (\"WIDE\", \"WIDER\", \"STRONG\", \"STRONGER\"), (\"WIDE\", \"WIDER\", \"WEAK\", \"WEAKER\")], \"correct\" => [(\"EASY\", \"EASIER\", \"LARGE\", \"LARGER\"), (\"EASY\", \"EASIER\", \"STRONG\", \"STRONGER\"), (\"FAST\", \"FASTER\", \"LOW\", \"LOWER\"), (\"GOOD\", \"BETTER\", \"LARGE\", \"LARGER\"), (\"GREAT\", \"GREATER\", \"LARGE\", \"LARGER\"), (\"GREAT\", \"GREATER\", \"LOW\", \"LOWER\"), (\"HIGH\", \"HIGHER\", \"LOW\", \"LOWER\"), (\"LARGE\", \"LARGER\", \"GREAT\", \"GREATER\"), (\"LARGE\", \"LARGER\", \"STRONG\", \"STRONGER\"), (\"LARGE\", \"LARGER\", \"WEAK\", \"WEAKER\")  …  (\"SHORT\", \"SHORTER\", \"LARGE\", \"LARGER\"), (\"SLOW\", \"SLOWER\", \"GREAT\", \"GREATER\"), (\"SLOW\", \"SLOWER\", \"LARGE\", \"LARGER\"), (\"SLOW\", \"SLOWER\", \"WEAK\", \"WEAKER\"), (\"SMALL\", \"SMALLER\", \"LARGE\", \"LARGER\"), (\"STRONG\", \"STRONGER\", \"LARGE\", \"LARGER\"), (\"STRONG\", \"STRONGER\", \"WEAK\", \"WEAKER\"), (\"WEAK\", \"WEAKER\", \"LARGE\", \"LARGER\"), (\"WIDE\", \"WIDER\", \"GREAT\", \"GREATER\"), (\"WIDE\", \"WIDER\", \"LARGE\", \"LARGER\")], \"section\" => \"gram3-comparative\")\n",
       " Dict(\"incorrect\" => [(\"GOOD\", \"BEST\", \"GREAT\", \"GREATEST\"), (\"GOOD\", \"BEST\", \"HIGH\", \"HIGHEST\"), (\"GOOD\", \"BEST\", \"LARGE\", \"LARGEST\"), (\"GOOD\", \"BEST\", \"LOW\", \"LOWEST\"), (\"GREAT\", \"GREATEST\", \"GOOD\", \"BEST\"), (\"GREAT\", \"GREATEST\", \"HIGH\", \"HIGHEST\"), (\"GREAT\", \"GREATEST\", \"LARGE\", \"LARGEST\"), (\"GREAT\", \"GREATEST\", \"LOW\", \"LOWEST\"), (\"HIGH\", \"HIGHEST\", \"GOOD\", \"BEST\"), (\"HIGH\", \"HIGHEST\", \"GREAT\", \"GREATEST\"), (\"HIGH\", \"HIGHEST\", \"LARGE\", \"LARGEST\"), (\"HIGH\", \"HIGHEST\", \"LOW\", \"LOWEST\"), (\"LARGE\", \"LARGEST\", \"GOOD\", \"BEST\"), (\"LARGE\", \"LARGEST\", \"GREAT\", \"GREATEST\"), (\"LARGE\", \"LARGEST\", \"HIGH\", \"HIGHEST\"), (\"LARGE\", \"LARGEST\", \"LOW\", \"LOWEST\"), (\"LOW\", \"LOWEST\", \"GOOD\", \"BEST\"), (\"LOW\", \"LOWEST\", \"GREAT\", \"GREATEST\"), (\"LOW\", \"LOWEST\", \"HIGH\", \"HIGHEST\"), (\"LOW\", \"LOWEST\", \"LARGE\", \"LARGEST\")], \"correct\" => Any[], \"section\" => \"gram4-superlative\")\n",
       " Dict(\"incorrect\" => [(\"DECREASE\", \"DECREASING\", \"ENHANCE\", \"ENHANCING\"), (\"DECREASE\", \"DECREASING\", \"GENERATE\", \"GENERATING\"), (\"DECREASE\", \"DECREASING\", \"IMPLEMENT\", \"IMPLEMENTING\"), (\"DECREASE\", \"DECREASING\", \"LOOK\", \"LOOKING\"), (\"DECREASE\", \"DECREASING\", \"READ\", \"READING\"), (\"DECREASE\", \"DECREASING\", \"WRITE\", \"WRITING\"), (\"ENHANCE\", \"ENHANCING\", \"DECREASE\", \"DECREASING\"), (\"ENHANCE\", \"ENHANCING\", \"GENERATE\", \"GENERATING\"), (\"ENHANCE\", \"ENHANCING\", \"IMPLEMENT\", \"IMPLEMENTING\"), (\"ENHANCE\", \"ENHANCING\", \"INCREASE\", \"INCREASING\")  …  (\"RUN\", \"RUNNING\", \"READ\", \"READING\"), (\"RUN\", \"RUNNING\", \"WRITE\", \"WRITING\"), (\"WRITE\", \"WRITING\", \"DECREASE\", \"DECREASING\"), (\"WRITE\", \"WRITING\", \"ENHANCE\", \"ENHANCING\"), (\"WRITE\", \"WRITING\", \"GENERATE\", \"GENERATING\"), (\"WRITE\", \"WRITING\", \"IMPLEMENT\", \"IMPLEMENTING\"), (\"WRITE\", \"WRITING\", \"INCREASE\", \"INCREASING\"), (\"WRITE\", \"WRITING\", \"LOOK\", \"LOOKING\"), (\"WRITE\", \"WRITING\", \"READ\", \"READING\"), (\"WRITE\", \"WRITING\", \"RUN\", \"RUNNING\")], \"correct\" => [(\"DECREASE\", \"DECREASING\", \"INCREASE\", \"INCREASING\"), (\"DECREASE\", \"DECREASING\", \"RUN\", \"RUNNING\")], \"section\" => \"gram5-present-participle\")\n",
       " Dict(\"incorrect\" => [(\"BRAZIL\", \"BRAZILIAN\", \"GERMANY\", \"GERMAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"RUSSIA\", \"RUSSIAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"SWITZERLAND\", \"SWISS\"), (\"CHINA\", \"CHINESE\", \"GERMANY\", \"GERMAN\"), (\"CHINA\", \"CHINESE\", \"ISRAEL\", \"ISRAELI\"), (\"CHINA\", \"CHINESE\", \"MEXICO\", \"MEXICAN\"), (\"CHINA\", \"CHINESE\", \"SWITZERLAND\", \"SWISS\"), (\"GERMANY\", \"GERMAN\", \"CHINA\", \"CHINESE\"), (\"GERMANY\", \"GERMAN\", \"INDIA\", \"INDIAN\"), (\"GERMANY\", \"GERMAN\", \"ISRAEL\", \"ISRAELI\")  …  (\"RUSSIA\", \"RUSSIAN\", \"ISRAEL\", \"ISRAELI\"), (\"RUSSIA\", \"RUSSIAN\", \"MEXICO\", \"MEXICAN\"), (\"RUSSIA\", \"RUSSIAN\", \"SWITZERLAND\", \"SWISS\"), (\"SWITZERLAND\", \"SWISS\", \"CHINA\", \"CHINESE\"), (\"SWITZERLAND\", \"SWISS\", \"GERMANY\", \"GERMAN\"), (\"SWITZERLAND\", \"SWISS\", \"ISRAEL\", \"ISRAELI\"), (\"SWITZERLAND\", \"SWISS\", \"JAPAN\", \"JAPANESE\"), (\"SWITZERLAND\", \"SWISS\", \"KOREA\", \"KOREAN\"), (\"SWITZERLAND\", \"SWISS\", \"MEXICO\", \"MEXICAN\"), (\"SWITZERLAND\", \"SWISS\", \"RUSSIA\", \"RUSSIAN\")], \"correct\" => [(\"BRAZIL\", \"BRAZILIAN\", \"CHINA\", \"CHINESE\"), (\"BRAZIL\", \"BRAZILIAN\", \"INDIA\", \"INDIAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"ISRAEL\", \"ISRAELI\"), (\"BRAZIL\", \"BRAZILIAN\", \"JAPAN\", \"JAPANESE\"), (\"BRAZIL\", \"BRAZILIAN\", \"KOREA\", \"KOREAN\"), (\"BRAZIL\", \"BRAZILIAN\", \"MEXICO\", \"MEXICAN\"), (\"CHINA\", \"CHINESE\", \"BRAZIL\", \"BRAZILIAN\"), (\"CHINA\", \"CHINESE\", \"INDIA\", \"INDIAN\"), (\"CHINA\", \"CHINESE\", \"JAPAN\", \"JAPANESE\"), (\"CHINA\", \"CHINESE\", \"KOREA\", \"KOREAN\")  …  (\"ISRAEL\", \"ISRAELI\", \"BRAZIL\", \"BRAZILIAN\"), (\"ISRAEL\", \"ISRAELI\", \"MEXICO\", \"MEXICAN\"), (\"KOREA\", \"KOREAN\", \"BRAZIL\", \"BRAZILIAN\"), (\"KOREA\", \"KOREAN\", \"JAPAN\", \"JAPANESE\"), (\"MEXICO\", \"MEXICAN\", \"BRAZIL\", \"BRAZILIAN\"), (\"MEXICO\", \"MEXICAN\", \"ISRAEL\", \"ISRAELI\"), (\"RUSSIA\", \"RUSSIAN\", \"JAPAN\", \"JAPANESE\"), (\"RUSSIA\", \"RUSSIAN\", \"KOREA\", \"KOREAN\"), (\"SWITZERLAND\", \"SWISS\", \"BRAZIL\", \"BRAZILIAN\"), (\"SWITZERLAND\", \"SWISS\", \"INDIA\", \"INDIAN\")], \"section\" => \"gram6-nationality-adjective\")\n",
       " Dict(\"incorrect\" => [(\"DECREASING\", \"DECREASED\", \"ENHANCING\", \"ENHANCED\"), (\"DECREASING\", \"DECREASED\", \"GENERATING\", \"GENERATED\"), (\"DECREASING\", \"DECREASED\", \"IMPLEMENTING\", \"IMPLEMENTED\"), (\"DECREASING\", \"DECREASED\", \"MOVING\", \"MOVED\"), (\"DECREASING\", \"DECREASED\", \"PAYING\", \"PAID\"), (\"DECREASING\", \"DECREASED\", \"READING\", \"READ\"), (\"DECREASING\", \"DECREASED\", \"SELLING\", \"SOLD\"), (\"DECREASING\", \"DECREASED\", \"SPENDING\", \"SPENT\"), (\"DECREASING\", \"DECREASED\", \"TAKING\", \"TOOK\"), (\"ENHANCING\", \"ENHANCED\", \"DECREASING\", \"DECREASED\")  …  (\"TAKING\", \"TOOK\", \"DECREASING\", \"DECREASED\"), (\"TAKING\", \"TOOK\", \"ENHANCING\", \"ENHANCED\"), (\"TAKING\", \"TOOK\", \"GENERATING\", \"GENERATED\"), (\"TAKING\", \"TOOK\", \"IMPLEMENTING\", \"IMPLEMENTED\"), (\"TAKING\", \"TOOK\", \"INCREASING\", \"INCREASED\"), (\"TAKING\", \"TOOK\", \"MOVING\", \"MOVED\"), (\"TAKING\", \"TOOK\", \"PAYING\", \"PAID\"), (\"TAKING\", \"TOOK\", \"READING\", \"READ\"), (\"TAKING\", \"TOOK\", \"SELLING\", \"SOLD\"), (\"TAKING\", \"TOOK\", \"SPENDING\", \"SPENT\")], \"correct\" => [(\"DECREASING\", \"DECREASED\", \"INCREASING\", \"INCREASED\"), (\"GENERATING\", \"GENERATED\", \"DECREASING\", \"DECREASED\"), (\"IMPLEMENTING\", \"IMPLEMENTED\", \"INCREASING\", \"INCREASED\"), (\"INCREASING\", \"INCREASED\", \"DECREASING\", \"DECREASED\"), (\"MOVING\", \"MOVED\", \"SELLING\", \"SOLD\")], \"section\" => \"gram7-past-tense\")\n",
       " Dict(\"incorrect\" => [(\"BUILDING\", \"BUILDINGS\", \"COMPUTER\", \"COMPUTERS\"), (\"BUILDING\", \"BUILDINGS\", \"DOLLAR\", \"DOLLARS\"), (\"BUILDING\", \"BUILDINGS\", \"MACHINE\", \"MACHINES\"), (\"BUILDING\", \"BUILDINGS\", \"MAN\", \"MEN\"), (\"CAR\", \"CARS\", \"BUILDING\", \"BUILDINGS\"), (\"CAR\", \"CARS\", \"COMPUTER\", \"COMPUTERS\"), (\"CAR\", \"CARS\", \"DOLLAR\", \"DOLLARS\"), (\"CAR\", \"CARS\", \"MACHINE\", \"MACHINES\"), (\"CAR\", \"CARS\", \"MAN\", \"MEN\"), (\"COMPUTER\", \"COMPUTERS\", \"BUILDING\", \"BUILDINGS\")  …  (\"MACHINE\", \"MACHINES\", \"BUILDING\", \"BUILDINGS\"), (\"MACHINE\", \"MACHINES\", \"CAR\", \"CARS\"), (\"MACHINE\", \"MACHINES\", \"COMPUTER\", \"COMPUTERS\"), (\"MACHINE\", \"MACHINES\", \"DOLLAR\", \"DOLLARS\"), (\"MACHINE\", \"MACHINES\", \"MAN\", \"MEN\"), (\"MAN\", \"MEN\", \"BUILDING\", \"BUILDINGS\"), (\"MAN\", \"MEN\", \"CAR\", \"CARS\"), (\"MAN\", \"MEN\", \"COMPUTER\", \"COMPUTERS\"), (\"MAN\", \"MEN\", \"DOLLAR\", \"DOLLARS\"), (\"MAN\", \"MEN\", \"MACHINE\", \"MACHINES\")], \"correct\" => [(\"BUILDING\", \"BUILDINGS\", \"CAR\", \"CARS\"), (\"COMPUTER\", \"COMPUTERS\", \"CAR\", \"CARS\"), (\"DOLLAR\", \"DOLLARS\", \"CAR\", \"CARS\")], \"section\" => \"gram8-plural\")\n",
       " Dict(\"incorrect\" => [(\"DECREASE\", \"DECREASES\", \"DESCRIBE\", \"DESCRIBES\"), (\"DECREASE\", \"DECREASES\", \"ENHANCE\", \"ENHANCES\"), (\"DECREASE\", \"DECREASES\", \"GENERATE\", \"GENERATES\"), (\"DECREASE\", \"DECREASES\", \"PLAY\", \"PLAYS\"), (\"DECREASE\", \"DECREASES\", \"PROVIDE\", \"PROVIDES\"), (\"DECREASE\", \"DECREASES\", \"WORK\", \"WORKS\"), (\"DESCRIBE\", \"DESCRIBES\", \"DECREASE\", \"DECREASES\"), (\"DESCRIBE\", \"DESCRIBES\", \"ENHANCE\", \"ENHANCES\"), (\"DESCRIBE\", \"DESCRIBES\", \"ESTIMATE\", \"ESTIMATES\"), (\"DESCRIBE\", \"DESCRIBES\", \"GENERATE\", \"GENERATES\")  …  (\"PROVIDE\", \"PROVIDES\", \"PLAY\", \"PLAYS\"), (\"PROVIDE\", \"PROVIDES\", \"WORK\", \"WORKS\"), (\"WORK\", \"WORKS\", \"DECREASE\", \"DECREASES\"), (\"WORK\", \"WORKS\", \"DESCRIBE\", \"DESCRIBES\"), (\"WORK\", \"WORKS\", \"ENHANCE\", \"ENHANCES\"), (\"WORK\", \"WORKS\", \"ESTIMATE\", \"ESTIMATES\"), (\"WORK\", \"WORKS\", \"GENERATE\", \"GENERATES\"), (\"WORK\", \"WORKS\", \"INCREASE\", \"INCREASES\"), (\"WORK\", \"WORKS\", \"PLAY\", \"PLAYS\"), (\"WORK\", \"WORKS\", \"PROVIDE\", \"PROVIDES\")], \"correct\" => [(\"DECREASE\", \"DECREASES\", \"ESTIMATE\", \"ESTIMATES\"), (\"DECREASE\", \"DECREASES\", \"INCREASE\", \"INCREASES\"), (\"DESCRIBE\", \"DESCRIBES\", \"PROVIDE\", \"PROVIDES\"), (\"ENHANCE\", \"ENHANCES\", \"ESTIMATE\", \"ESTIMATES\"), (\"ENHANCE\", \"ENHANCES\", \"PROVIDE\", \"PROVIDES\"), (\"INCREASE\", \"INCREASES\", \"DECREASE\", \"DECREASES\"), (\"INCREASE\", \"INCREASES\", \"ESTIMATE\", \"ESTIMATES\")], \"section\" => \"gram9-plural-verbs\")\n",
       " Dict(\"incorrect\" => [(\"CHICAGO\", \"ILLINOIS\", \"DALLAS\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"SEATTLE\", \"WASHINGTON\"), (\"CHICAGO\", \"ILLINOIS\", \"CINCINNATI\", \"OHIO\"), (\"HOUSTON\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"HOUSTON\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"DALLAS\", \"TEXAS\", \"SEATTLE\", \"WASHINGTON\"), (\"DALLAS\", \"TEXAS\", \"ATLANTA\", \"GEORGIA\"), (\"DALLAS\", \"TEXAS\", \"CINCINNATI\", \"OHIO\"), (\"BOSTON\", \"MASSACHUSETTS\", \"HOUSTON\", \"TEXAS\")  …  (\"PROVIDE\", \"PROVIDES\", \"PLAY\", \"PLAYS\"), (\"PROVIDE\", \"PROVIDES\", \"WORK\", \"WORKS\"), (\"WORK\", \"WORKS\", \"DECREASE\", \"DECREASES\"), (\"WORK\", \"WORKS\", \"DESCRIBE\", \"DESCRIBES\"), (\"WORK\", \"WORKS\", \"ENHANCE\", \"ENHANCES\"), (\"WORK\", \"WORKS\", \"ESTIMATE\", \"ESTIMATES\"), (\"WORK\", \"WORKS\", \"GENERATE\", \"GENERATES\"), (\"WORK\", \"WORKS\", \"INCREASE\", \"INCREASES\"), (\"WORK\", \"WORKS\", \"PLAY\", \"PLAYS\"), (\"WORK\", \"WORKS\", \"PROVIDE\", \"PROVIDES\")], \"correct\" => [(\"CHICAGO\", \"ILLINOIS\", \"HOUSTON\", \"TEXAS\"), (\"CHICAGO\", \"ILLINOIS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"CHICAGO\", \"ILLINOIS\", \"ATLANTA\", \"GEORGIA\"), (\"HOUSTON\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"HOUSTON\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"DALLAS\", \"TEXAS\", \"CHICAGO\", \"ILLINOIS\"), (\"DALLAS\", \"TEXAS\", \"BOSTON\", \"MASSACHUSETTS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"CHICAGO\", \"ILLINOIS\"), (\"BOSTON\", \"MASSACHUSETTS\", \"ATLANTA\", \"GEORGIA\"), (\"SEATTLE\", \"WASHINGTON\", \"CHICAGO\", \"ILLINOIS\")  …  (\"BUILDING\", \"BUILDINGS\", \"CAR\", \"CARS\"), (\"COMPUTER\", \"COMPUTERS\", \"CAR\", \"CARS\"), (\"DOLLAR\", \"DOLLARS\", \"CAR\", \"CARS\"), (\"DECREASE\", \"DECREASES\", \"ESTIMATE\", \"ESTIMATES\"), (\"DECREASE\", \"DECREASES\", \"INCREASE\", \"INCREASES\"), (\"DESCRIBE\", \"DESCRIBES\", \"PROVIDE\", \"PROVIDES\"), (\"ENHANCE\", \"ENHANCES\", \"ESTIMATE\", \"ESTIMATES\"), (\"ENHANCE\", \"ENHANCES\", \"PROVIDE\", \"PROVIDES\"), (\"INCREASE\", \"INCREASES\", \"DECREASE\", \"DECREASES\"), (\"INCREASE\", \"INCREASES\", \"ESTIMATE\", \"ESTIMATES\")], \"section\" => \"Total accuracy\")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_accuracy = best_model.wv.evaluate_word_analogies(normpath(analogies_path), case_insensitive=true)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.760326Z",
     "start_time": "2020-06-21T14:57:52.728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15×4 DataFrame\n",
      "│ Row │ category                    │ correct │ incorrect │ average   │\n",
      "│     │ \u001b[90mString\u001b[39m                      │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n",
      "├─────┼─────────────────────────────┼─────────┼───────────┼───────────┤\n",
      "│ 1   │ capital-common-countries    │ 0       │ 0         │ NaN       │\n",
      "│ 2   │ capital-world               │ 0       │ 0         │ NaN       │\n",
      "│ 3   │ family                      │ 0       │ 0         │ NaN       │\n",
      "│ 4   │ city-in-state               │ 19      │ 21        │ 0.475     │\n",
      "│ 5   │ gram6-nationality-adjective │ 27      │ 63        │ 0.3       │\n",
      "│ 6   │ Total accuracy              │ 87      │ 707       │ 0.109572  │\n",
      "│ 7   │ gram8-plural                │ 3       │ 27        │ 0.1       │\n",
      "│ 8   │ gram9-plural-verbs          │ 7       │ 65        │ 0.0972222 │\n",
      "│ 9   │ gram3-comparative           │ 23      │ 217       │ 0.0958333 │\n",
      "│ 10  │ gram7-past-tense            │ 5       │ 105       │ 0.0454545 │\n",
      "│ 11  │ gram5-present-participle    │ 2       │ 70        │ 0.0277778 │\n",
      "│ 12  │ gram1-adjective-to-adverb   │ 1       │ 71        │ 0.0138889 │\n",
      "│ 13  │ currency                    │ 0       │ 18        │ 0.0       │\n",
      "│ 14  │ gram2-opposite              │ 0       │ 30        │ 0.0       │\n",
      "│ 15  │ gram4-superlative           │ 0       │ 20        │ 0.0       │\n",
      "\n",
      "Base Accuracy: Correct 87 | Wrong 707 | Avg 0.10957178841309824\n"
     ]
    }
   ],
   "source": [
    "summary = accuracy_by_category(detailed_accuracy)\n",
    "println(\"\\nBase Accuracy: Correct $(summary[1]) | Wrong $(summary[2]) | Avg $(summary[3])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.760862Z",
     "start_time": "2020-06-21T14:57:52.730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, String} with 15 entries:\n",
       "  \"capital-common-countries\"    => \"Capitals\"\n",
       "  \"gram5-present-participle\"    => \"Pres. Part.\"\n",
       "  \"family\"                      => \"Famliy\"\n",
       "  \"gram7-past-tense\"            => \"Past Tense\"\n",
       "  \"gram8-plural\"                => \"Plural\"\n",
       "  \"gram2-opposite\"              => \"Opposite\"\n",
       "  \"total\"                       => \"Total\"\n",
       "  \"city-in-state\"               => \"City-State\"\n",
       "  \"gram3-comparative\"           => \"Comparative\"\n",
       "  \"gram1-adjective-to-adverb\"   => \"Adj-Adverb\"\n",
       "  \"gram4-superlative\"           => \"Superlative\"\n",
       "  \"gram6-nationality-adjective\" => \"Nationality\"\n",
       "  \"currency\"                    => \"Currency\"\n",
       "  \"capital-world\"               => \"Capitals RoW\"\n",
       "  \"gram9-plural-verbs\"          => \"Plural Verbs\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dict = Dict(\"capital-common-countries\" => \"Capitals\",\n",
    "            \"capital-world\" => \"Capitals RoW\",\n",
    "            \"city-in-state\" => \"City-State\",\n",
    "            \"currency\" => \"Currency\",\n",
    "            \"family\" => \"Famliy\",\n",
    "            \"gram1-adjective-to-adverb\" => \"Adj-Adverb\",\n",
    "            \"gram2-opposite\" => \"Opposite\",\n",
    "            \"gram3-comparative\" => \"Comparative\",\n",
    "            \"gram4-superlative\" => \"Superlative\",\n",
    "            \"gram5-present-participle\" => \"Pres. Part.\",\n",
    "            \"gram6-nationality-adjective\" => \"Nationality\",\n",
    "            \"gram7-past-tense\" => \"Past Tense\",\n",
    "            \"gram8-plural\" => \"Plural\",\n",
    "            \"gram9-plural-verbs\" => \"Plural Verbs\",\n",
    "            \"total\" => \"Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.761465Z",
     "start_time": "2020-06-21T14:57:52.732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14×4 DataFrame\n",
      "│ Row │ Category     │ Correct │ Incorrect │ Average   │\n",
      "│     │ \u001b[90mString\u001b[39m       │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n",
      "├─────┼──────────────┼─────────┼───────────┼───────────┤\n",
      "│ 1   │ Capitals     │ 0       │ 0         │ NaN       │\n",
      "│ 2   │ Capitals RoW │ 0       │ 0         │ NaN       │\n",
      "│ 3   │ City-State   │ 19      │ 21        │ 0.475     │\n",
      "│ 4   │ Currency     │ 0       │ 18        │ 0.0       │\n",
      "│ 5   │ Famliy       │ 0       │ 0         │ NaN       │\n",
      "│ 6   │ Adj-Adverb   │ 1       │ 71        │ 0.0138889 │\n",
      "│ 7   │ Opposite     │ 0       │ 30        │ 0.0       │\n",
      "│ 8   │ Comparative  │ 23      │ 217       │ 0.0958333 │\n",
      "│ 9   │ Superlative  │ 0       │ 20        │ 0.0       │\n",
      "│ 10  │ Pres. Part.  │ 2       │ 70        │ 0.0277778 │\n",
      "│ 11  │ Nationality  │ 27      │ 63        │ 0.3       │\n",
      "│ 12  │ Past Tense   │ 5       │ 105       │ 0.0454545 │\n",
      "│ 13  │ Plural       │ 3       │ 27        │ 0.1       │\n",
      "│ 14  │ Plural Verbs │ 7       │ 65        │ 0.0972222 │\n",
      "\n",
      " Total: 1×4 DataFrame\n",
      "│ Row │ Category       │ Correct │ Incorrect │ Average  │\n",
      "│     │ String         │ Int64   │ Int64     │ Float64  │\n",
      "├─────┼────────────────┼─────────┼───────────┼──────────┤\n",
      "│ 1   │ Total accuracy │ 87      │ 707       │ 0.109572 │\n"
     ]
    }
   ],
   "source": [
    "results = [[c[\"section\"], length(c[\"correct\"]), length(c[\"incorrect\"])] for c ∈ detailed_accuracy]\n",
    "results = DataFrame(category=[result[1] for result ∈ results], \n",
    "                    correct=[result[2] for result ∈ results], \n",
    "                    incorrect=[result[3] for result ∈ results])\n",
    "\n",
    "for item ∈ keys(cat_dict)\n",
    "    replace!(results[!, \"category\"], item => cat_dict[item])\n",
    "end\n",
    "\n",
    "results[!, \"average\"] = results.correct./sum.(eachrow(results[:, [\"correct\", \"incorrect\"]]))\n",
    "rename!(results, uppercasefirst.(names(results)))\n",
    "total = filter(row -> row.Category == \"Total accuracy\", results)\n",
    "results = filter(row -> row.Category != \"Total accuracy\", results)\n",
    "println(results)\n",
    "println(\"\\n Total: $(total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.762031Z",
     "start_time": "2020-06-21T14:57:52.734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>token</th><th>similarity</th></tr><tr><th></th><th>String</th><th>Float64</th></tr></thead><tbody><p>20 rows × 2 columns</p><tr><th>1</th><td>sweden</td><td>0.490823</td></tr><tr><th>2</th><td>germany</td><td>0.489274</td></tr><tr><th>3</th><td>kingdom</td><td>0.486661</td></tr><tr><th>4</th><td>netherlands</td><td>0.462996</td></tr><tr><th>5</th><td>italy</td><td>0.413548</td></tr><tr><th>6</th><td>canada</td><td>0.409447</td></tr><tr><th>7</th><td>singapore</td><td>0.399187</td></tr><tr><th>8</th><td>spain</td><td>0.394387</td></tr><tr><th>9</th><td>india</td><td>0.388033</td></tr><tr><th>10</th><td>japan</td><td>0.385139</td></tr><tr><th>11</th><td>switzerland</td><td>0.37539</td></tr><tr><th>12</th><td>mexico</td><td>0.366685</td></tr><tr><th>13</th><td>brazil</td><td>0.364864</td></tr><tr><th>14</th><td>australia</td><td>0.354722</td></tr><tr><th>15</th><td>european</td><td>0.348283</td></tr><tr><th>16</th><td>korea</td><td>0.341751</td></tr><tr><th>17</th><td>belgium</td><td>0.341639</td></tr><tr><th>18</th><td>china</td><td>0.332982</td></tr><tr><th>19</th><td>uk</td><td>0.328233</td></tr><tr><th>20</th><td>distribution</td><td>0.32756</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& token & similarity\\\\\n",
       "\t\\hline\n",
       "\t& String & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & sweden & 0.490823 \\\\\n",
       "\t2 & germany & 0.489274 \\\\\n",
       "\t3 & kingdom & 0.486661 \\\\\n",
       "\t4 & netherlands & 0.462996 \\\\\n",
       "\t5 & italy & 0.413548 \\\\\n",
       "\t6 & canada & 0.409447 \\\\\n",
       "\t7 & singapore & 0.399187 \\\\\n",
       "\t8 & spain & 0.394387 \\\\\n",
       "\t9 & india & 0.388033 \\\\\n",
       "\t10 & japan & 0.385139 \\\\\n",
       "\t11 & switzerland & 0.37539 \\\\\n",
       "\t12 & mexico & 0.366685 \\\\\n",
       "\t13 & brazil & 0.364864 \\\\\n",
       "\t14 & australia & 0.354722 \\\\\n",
       "\t15 & european & 0.348283 \\\\\n",
       "\t16 & korea & 0.341751 \\\\\n",
       "\t17 & belgium & 0.341639 \\\\\n",
       "\t18 & china & 0.332982 \\\\\n",
       "\t19 & uk & 0.328233 \\\\\n",
       "\t20 & distribution & 0.32756 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "20×2 DataFrame\n",
       "│ Row │ token        │ similarity │\n",
       "│     │ \u001b[90mString\u001b[39m       │ \u001b[90mFloat64\u001b[39m    │\n",
       "├─────┼──────────────┼────────────┤\n",
       "│ 1   │ sweden       │ 0.490823   │\n",
       "│ 2   │ germany      │ 0.489274   │\n",
       "│ 3   │ kingdom      │ 0.486661   │\n",
       "│ 4   │ netherlands  │ 0.462996   │\n",
       "│ 5   │ italy        │ 0.413548   │\n",
       "│ 6   │ canada       │ 0.409447   │\n",
       "│ 7   │ singapore    │ 0.399187   │\n",
       "│ 8   │ spain        │ 0.394387   │\n",
       "│ 9   │ india        │ 0.388033   │\n",
       "│ 10  │ japan        │ 0.385139   │\n",
       "│ 11  │ switzerland  │ 0.37539    │\n",
       "│ 12  │ mexico       │ 0.366685   │\n",
       "│ 13  │ brazil       │ 0.364864   │\n",
       "│ 14  │ australia    │ 0.354722   │\n",
       "│ 15  │ european     │ 0.348283   │\n",
       "│ 16  │ korea        │ 0.341751   │\n",
       "│ 17  │ belgium      │ 0.341639   │\n",
       "│ 18  │ china        │ 0.332982   │\n",
       "│ 19  │ uk           │ 0.328233   │\n",
       "│ 20  │ distribution │ 0.32756    │"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim = best_model.wv.most_similar(positive=[\"france\", \"london\"], negative=[\"london\"], topn=20)\n",
    "most_sim_df = DataFrame(token=[pair[1] for pair ∈ most_sim], \n",
    "                        similarity=[pair[2] for pair ∈ most_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T15:24:59.762602Z",
     "start_time": "2020-06-21T14:57:52.735Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fig, axes = plt.subplots(figsize=(16, 5), ncols=2)\n",
    "\n",
    "axes[0] = results.loc[:, [\"Correct\", \"Incorrect\"]].plot.bar(stacked=True, ax=axes[0]\n",
    "                                                           , title=\"Analogy Accuracy\")\n",
    "ax1 = results.loc[:, [\"Average\"]].plot(ax=axes[0], secondary_y=True, lw=1, c=\"k\", rot=35)\n",
    "ax1.yaxis.set_major_formatter(FuncFormatter(lambda y, _: \"{:.0%}\".format(y)))\n",
    "\n",
    "(pd.DataFrame(most_sim, columns=[\"token\", \"similarity\"])\n",
    " .set_index(\"token\").similarity\n",
    " .sort_values().tail(10).plot.barh(xlim=(.3, .37), ax=axes[1], title=\"Closest matches for Woman + King - Man\"))\n",
    "fig.tight_layout();\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
